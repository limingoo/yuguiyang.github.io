<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[博客迁移整理中(置顶)]]></title>
    <url>%2F2017%2F12%2F31%2Ftop%2F</url>
    <content type="text"><![CDATA[Hi，欢迎访问我的博客。最近正在迁移文章到这里，不定时更新中，请期待。]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL-聚合函数]]></title>
    <url>%2F2017%2F09%2F11%2Fmysql-handbook-09%2F</url>
    <content type="text"><![CDATA[MySQL聚合函数 聚合函数也是函数的一种，比较常用，这里我们就单独拿出来介绍下。聚合函数一般配合group by来使用，经常是用来对数据集中的数值求和、平均值啊这里类的。 聚合函数的默认特性 忽略NULL值 如果没有匹配的记录，返回NULL 如果没有使用group by，则默认对所有字段进行group by 常用聚合函数这里的测试数据依然使用前面的数据，可以参考前面的文章。 count统计结果集的数量,没有结果时，返回012345678910111213-- 我们以学生表为例，来统计每个班级的学生人数select c_id,count(1), count(s_id), -- 这里学生ID是唯一的，所以是否使用distinct是一样的 count(distinct s_id), -- 统计班级的个数 count(distinct c_id)from t_student group by c_id; 当我们只使用count，不使用group by的时候，相当于对所有字段进行group by12345select count(1)from t_student; 这里，我们再来看下count对于null值得处理1234567891011121314select -- count(*),是包括null值的 count(*), -- count(1),也包括null值 count(1), -- 指定字段的时候，是不包括null值的 count(id), -- 同样也不包括null值 count(DISTINCT id)from ( select 1 as id union select NULL union select 2)x avg、sum计算结果集的平局值和结果集的累加和12345678910-- 统计每个学生的平均分和总分select s_id, avg(score), sum(score) from t_scoregroup by s_id; 我们再来看看avg和sum对null值的处理1234567891011121314select -- count指定字段，是不包括null值的 count(score), -- avg也是不包括null值的 avg(score), -- 如果想要统计score的记录，需要使用ifnull进行判断 avg(IFNULL(score,0)), -- 求和 sum(score)from ( select 10 as score union select NULL union select 20)x; min、max统计结果集的最小值和最大值123456789101112select s_id, -- 最低分 min(score), -- 最高分 max(score)from t_scoregroup by s_id; 如果没有匹配的记录，则返回null；如果结果集中有null值，会忽略null123456789select max(score), min(score)from ( select 10 as score union select NULL union select 20)x; group_concatgroup_concat会将函数聚合后的所有值以逗号分隔，以字符串展现1234GROUP_CONCAT([DISTINCT] expr [,expr ...] [ORDER BY &#123;unsigned_integer | col_name | expr&#125; [ASC | DESC] [,col_name ...]] [SEPARATOR str_val]) 123456789select s_id, -- 将该学生所有的成绩以逗号分隔显示 group_concat(score)from t_scoregroup by s_id; having在聚合函数的使用过程中，通常还会使用having来对聚合后的数据进行过滤12345678910select s_id, sum(score) sum_scorefrom t_scoregroup by s_id-- 总分大于150分having sum_score &gt; 150]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>SQL</tag>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL-子查询的使用]]></title>
    <url>%2F2017%2F09%2F11%2Fmysql-handbook-08%2F</url>
    <content type="text"><![CDATA[MySQL变量的使用 什么是子查询子查询是将一个 SELECT 语句的查询结果作为中间结果，供另一个 SQL 语句调用。像这样：12-- 我们将学生表中的所有班级ID当做中间结果select *from t_class where c_id in (select distinct c_id from t_student); 常用比较符子查询最常用的用法： non_subquery_operand comparison_operator (subquery)其中操作符通常为= &gt; &lt; &gt;= &lt;= &lt;&gt; != &lt;=&gt; 其他的都不说了，这里说下这个&lt;=&gt;,以前还真没用过&lt;=&gt;和=比较类似，也是判断是否相等，相等返回1，不相等返回2123456789101112131415mysql&gt; select 1&lt;=&gt;1,1&lt;=&gt;2;+-------+-------+| 1&lt;=&gt;1 | 1&lt;=&gt;2 |+-------+-------+| 1 | 0 |+-------+-------+1 row in setmysql&gt; select 1=1,1=2;+-----+-----+| 1=1 | 1=2 |+-----+-----+| 1 | 0 |+-----+-----+1 row in set 和=不一样的地方，是对NULL的支持，用&lt;=&gt;可以判断是否为null，而等号则是出现null，结果就为null1234567mysql&gt; select 1&lt;=&gt;null,null&lt;=&gt;null,1=null,null=null;+----------+-------------+--------+-----------+| 1&lt;=&gt;null | null&lt;=&gt;null | 1=null | null=null |+----------+-------------+--------+-----------+| 0 | 1 | NULL | NULL |+----------+-------------+--------+-----------+1 row in set any、in、some在子查询中，in平时用的比较多，这个any、some，这里简单说下any和some operand comparison_operator ANY (subquery)operand comparison_operator SOME (subquery)可以为 = > < >= all ()：表示大于所有值，即&gt;子查询中最大值&lt; all() : 表示小于所有值，即&lt; 子查询中的最小值= all(): 返回单个值时和=一样，返回多个值时貌似没啥用&lt;&gt; all(): 和not in 一样 1234select *from t_student where s_id &gt; all( select s_id from t_student where s_id in (105,109)); 标量子查询这种情况下，子查询返回单个值，可以在任何地方使用它。1234567891011121314select c_id, c_name, (select max(s_id) from t_student) as max_s_idfrom t_class;select *from t_class where c_id = (select max(c_id) from t_class); 行子查询上面我们介绍的子查询，都是返回1列多行，行子查询的话，是返回1行多列123-- 查询一班所有男生select *from t_studentwhere (c_id,s_gender) = (901,0); 这里也可以返回多行多列（也叫做表子查询）12select *from t_studentwhere (c_id,s_gender) in (select 901,0 union select 902,0); 参考资料官方文档：https://dev.mysql.com/doc/refman/5.7/en/subqueries.html]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>SQL</tag>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[小白学习Tableau-使用计算进行聚焦]]></title>
    <url>%2F2017%2F09%2F10%2FTableau-handbook-05%2F</url>
    <content type="text"><![CDATA[Tableau实例 什么是聚焦聚焦是一种技术，用于根据某个度量的值显示离散阈值。聚焦计算其实是一种可产生离散度量的特殊计算。 其实就是新构造了一个维度，这个维度将度量值进行分段，类似于年龄段这样的维度。这个应用场景很多，比如我们有一个达标值，想要哪些数据达标，哪些未达标。 实例数据源使用Tableau中自带的“示例-超市”，其中的订单表 交叉列表我们来看每个地区，每个子类别的数量 现在，我们想要实现这样的功能，就是我有一个达标值500，只有数量达到500，才达标，怎样展示最好呢？ 创建计算字段我们来创建一个计算字段，如果数量大于500则达标，否则不达标 然后，把他拖到颜色上 到这里，我们就可以看到，已经按照Good、Bad来区分颜色，达标、不达标 使用参数上面，我们已经达成了目的，思考下，这个达标值的问题，这个月是500，下个月可能会浮动为600或者400，但我们在代码中写死了500，不够灵活，我们就可以使用参数来控制。 然后，我们修改上面的计算字段 好了，最后，我们就可以动态的修改这个达标值了 参考官方文档：示例 — 使用计算进行聚焦]]></content>
      <categories>
        <category>Tableau</category>
      </categories>
      <tags>
        <tag>数据可视化</tag>
        <tag>Tableau</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL-变量的使用]]></title>
    <url>%2F2017%2F09%2F10%2Fmysql-handbook-07%2F</url>
    <content type="text"><![CDATA[MySQL变量的使用 这里，我们简单介绍下MySQL中变量的使用 变量的作用域在MySQL中，变量的作用域主要有全局变量（Global）和会话级变量（Session）全局变量会影响当前server上的所有操作，而会话级变量则只会影响当前用户的会话，server上其他用户的会话不受影响 系统变量系统变量主要涉及MySQL Server的一些配置参数，系统变量，一般会在配置文件中进行配置，或者在使用命令启动MySQL的使用去指定。当然，在MySQL启动后，也可以动态的去修改系统变量（有些变量是不能动态修改的，可以修改的变量请参照官方文档）。 那我们怎样动态的修改系统变量呢？可以使用 SET GLOBAL or SET SESSION@@global. | @@session. 123456SET GLOBAL max_connections = 1000;SET @@global.max_connections = 1000;SET SESSION sql_mode = 'TRADITIONAL';SET @@session.sql_mode = 'TRADITIONAL';SET @@sql_mode = 'TRADITIONAL'; 查看当前系统变量的值1234567SHOW VARIABLES;SHOW VARIABLES LIKE 'max_join_size';SHOW SESSION VARIABLES LIKE 'max_join_size';SHOW VARIABLES LIKE '%size%';SHOW GLOBAL VARIABLES LIKE '%size%'; 用户自定义变量我们可以定义自己的变量，变量名为 @var_name，用户自定义变量都是会话级的 SET @var_name = expr [, @var_name = expr] …For SET, either = or := can be used as the assignment operator. 我们也可以使用select来使用变量，或者给变量赋值，但必须使用:=12345678910mysql&gt; SET @t1=1, @t2=2, @t3:=4;Query OK, 0 rows affectedmysql&gt; SELECT @t1, @t2, @t3, @t4 := @t1+@t2+@t3;+-----+-----+-----+--------------------+| @t1 | @t2 | @t3 | @t4 := @t1+@t2+@t3 |+-----+-----+-----+--------------------+| 1 | 2 | 4 | 7 |+-----+-----+-----+--------------------+1 row in set 在使用自定义变量的时候，会有一个顺序的问题，12set @p_rank:= 0;select *,@p_rank,@p_rank:=@p_rank+1 from t_student; 这样虽然可以得到我们想要的结果，但是官方并不推荐 自定义变量，是在结果返回到客户端时，才进行处理的，所以我们HAVING, GROUP BY, or ORDER BY中使用的时候，并没有效果。 参考资料官方文档：user-variablesserver-system-variables]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>SQL</tag>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL-常用函数]]></title>
    <url>%2F2017%2F09%2F10%2Fmysql-handbook-06%2F</url>
    <content type="text"><![CDATA[MySQL常用函数 这里介绍下，MySQL中常用的函数，函数有太多太多，不一定都需要记住，只需要有个印象，需要的时候去文档中找一下，记住一些常用的就好了 数学函数abs(x)返回x的绝对值1select abs(-10),abs(10) ceil(x)、ceiling(x)向上取整,比该值大的第一个整数1select CEIL(9.3),CEIL(9.5),CEIL(9.6),CEIL(-9.5),CEIL(-9.1) floor(x)向下取整，比该值小的第一个整数 1select FLOOR(9.3),FLOOR(9.5),FLOOR(9.6),FLOOR(-9.5),FLOOR(-9.1) round(x),round(x,y)四舍五入，round(x)，最近的一个整数，round(x,y)，这个y可以指定精度 1select ROUND(9.3),ROUND(9.6),ROUND(9.378,2),ROUND(9.455,2) rand(),rand(x)rand() 返回0~1之间的随机数rand(x) 返回0~1之间的随机数，如果x值相等，则返回值相等 1select RAND(),RAND(),RAND(10),RAND(10) 字符串函数获取字符串长度 length(str)，返回str的长度,这里要注意下中文，占3个长度,这里的长度单位是bytes1234567mysql&gt; select length('abc'),length('中国'),length('hi中国');+---------------+----------------+------------------+| length('abc') | length('中国') | length('hi中国') |+---------------+----------------+------------------+| 3 | 6 | 8 |+---------------+----------------+------------------+1 row in set CHAR_LENGTH(str)，返回str的长度，中文和英文一样，占1个字符，这里长度单位是字符1234567mysql&gt; select char_length('abc'),char_length('中国'),char_length('hi中国');+--------------------+---------------------+-----------------------+| char_length('abc') | char_length('中国') | char_length('hi中国') |+--------------------+---------------------+-----------------------+| 3 | 2 | 4 |+--------------------+---------------------+-----------------------+1 row in set 字符串拼接CONCAT(str1,str2,…)，将str1，str2拼接在一起12345678mysql&gt; select concat('h','e','gogo','中国');+-------------------------------+| concat('h','e','gogo','中国') |+-------------------------------+| hegogo中国 |+-------------------------------+1 row in set 这里要注意下NULL，如果其中有参数为NULL，则结果为NULL1234567mysql&gt; select concat('h','e','gogo',NULL,'中国');+------------------------------------+| concat('h','e','gogo',NULL,'中国') |+------------------------------------+| NULL |+------------------------------------+1 row in set CONCAT_WS(separator,str1,str2,…)，使用指定的separator进行拼接1234567mysql&gt; select concat_ws('^','e','gogo',NULL,'中国');+---------------------------------------+| concat_ws('^','e','gogo',NULL,'中国') |+---------------------------------------+| e^gogo^中国 |+---------------------------------------+1 row in set 这里是如果有NULL，对结果是没有影响的，会直接忽略NULL值 剔除空格或指定字符剔除字符串左右的空格ltrim(str),剔除左侧空格rtrim(str),剔除右侧空格TRIM([{BOTH | LEADING | TRAILING} [remstr] FROM] str), TRIM([remstr FROM] str)trim可以使用参数来控制剔除空格或者是指定的remstr，默认是空格123456789101112131415mysql&gt; select concat(ltrim(' hi '),'oo'),concat(rtrim(' hi '),'oo'),concat(trim(' hi '),'oo');+--------------------------------+--------------------------------+-------------------------------+| concat(ltrim(' hi '),'oo') | concat(rtrim(' hi '),'oo') | concat(trim(' hi '),'oo') |+--------------------------------+--------------------------------+-------------------------------+| hi oo | hioo | hioo |+--------------------------------+--------------------------------+-------------------------------+1 row in setmysql&gt; select trim('a' from 'aabbbccaa'),trim(leading 'a' from 'aabbbccaa'),trim(trailing 'a' from 'aabbbccaa');+----------------------------+------------------------------------+-------------------------------------+| trim('a' from 'aabbbccaa') | trim(leading 'a' from 'aabbbccaa') | trim(trailing 'a' from 'aabbbccaa') |+----------------------------+------------------------------------+-------------------------------------+| bbbcc | bbbccaa | aabbbcc |+----------------------------+------------------------------------+-------------------------------------+1 row in set 字符串填充LPAD(str,len,padstr)，左侧填充RPAD(str,len,padstr)，右侧填充len是指定str的长度，如果不够，则使用padstr填充，如果超了，则进行截取1234567mysql&gt; select lpad('hi',6,'@'),lpad('higogo',4,'@'),rpad('hi',6,'@'),rpad('higogo',4,'@');+------------------+----------------------+------------------+----------------------+| lpad('hi',6,'@') | lpad('higogo',4,'@') | rpad('hi',6,'@') | rpad('higogo',4,'@') |+------------------+----------------------+------------------+----------------------+| @@@@hi | higo | hi@@@@ | higo |+------------------+----------------------+------------------+----------------------+1 row in set 字符串截取LEFT(str,len)，从左侧开始截取len个字符RIGHT(str,len)，从右侧截取len个字符SUBSTR(str,pos), SUBSTR(str FROM pos), SUBSTR(str,pos,len), SUBSTR(str FROM pos FOR len)，从指定pos开始截取len个字符1234567891011121314151617181920212223mysql&gt; select left('hello',1),left('hello',3),right('hello',3);+-----------------+-----------------+------------------+| left('hello',1) | left('hello',3) | right('hello',3) |+-----------------+-----------------+------------------+| h | hel | llo |+-----------------+-----------------+------------------+1 row in setmysql&gt; select substr('hello',1),substr('hello',2),substr('hello' from 2);+-------------------+-------------------+------------------------+| substr('hello',1) | substr('hello',2) | substr('hello' from 2) |+-------------------+-------------------+------------------------+| hello | ello | ello |+-------------------+-------------------+------------------------+1 row in setmysql&gt; select substr('hello',1,3),substr('hello',2,3),substr('hello' from 2 for 2);+---------------------+---------------------+------------------------------+| substr('hello',1,3) | substr('hello',2,3) | substr('hello' from 2 for 2) |+---------------------+---------------------+------------------------------+| hel | ell | el |+---------------------+---------------------+------------------------------+1 row in set 大小写转换LOWER(str) LCASE(str)，将str转为小写UPPER(str) UCASE(str)，将str转为大写1234567mysql&gt; select lower('AppLE'),lcase('AppLE'),upper('AppLE'),ucase('AppLE');+----------------+----------------+----------------+----------------+| lower('AppLE') | lcase('AppLE') | upper('AppLE') | ucase('AppLE') |+----------------+----------------+----------------+----------------+| apple | apple | APPLE | APPLE |+----------------+----------------+----------------+----------------+1 row in set 更多字符串函数参考官网： https://dev.mysql.com/doc/refman/5.7/en/string-functions.html 日期和函数获取当前日期、时间1SELECT CURRENT_DATE,CURRENT_DATE(),CURRENT_TIME,CURRENT_TIME(),CURRENT_TIMESTAMP(),NOW() 时间戳相关函数UNIX_TIMESTAMP() 返回当前时间的时间戳，UNIX_TIMESTAMP(x) 返回指定日期的时间戳FROM_UNIXTIME(x) 将时间戳转为日期FROM_UNIXTIME(x,y) 将时间戳转为指定格式的日期 1234567891011121314151617mysql&gt; select UNIX_TIMESTAMP(),UNIX_TIMESTAMP('2017-09-10');+------------------+------------------------------+| UNIX_TIMESTAMP() | UNIX_TIMESTAMP('2017-09-10') |+------------------+------------------------------+| 1505096065 | 1504972800 |+------------------+------------------------------+1 row in setmysql&gt; select FROM_UNIXTIME(1505096033),FROM_UNIXTIME(1504972800),FROM_UNIXTIME(1505096033,'%Y-%m-%d');+---------------------------+---------------------------+--------------------------------------+| FROM_UNIXTIME(1505096033) | FROM_UNIXTIME(1504972800) | FROM_UNIXTIME(1505096033,'%Y-%m-%d') |+---------------------------+---------------------------+--------------------------------------+| 2017-09-11 10:13:53 | 2017-09-10 00:00:00 | 2017-09-11 |+---------------------------+---------------------------+--------------------------------------+1 row in setmysql&gt; extractEXTRACT(unit FROM date)返回日期/时间的单独部分，比如年、月、日、小时、分钟等等date 参数是合法的日期表达式。unit 参数可以是下列的值： 123456789mysql&gt; select extract(YEAR FROM NOW()),extract(MONTH from now()),extract(HOUR from now());+--------------------------+---------------------------+--------------------------+| extract(YEAR FROM NOW()) | extract(MONTH from now()) | extract(HOUR from now()) |+--------------------------+---------------------------+--------------------------+| 2017 | 9 | 10 |+--------------------------+---------------------------+--------------------------+1 row in setmysql&gt; datediff、timediff、timestampdiffdatediff(expr1,expr2),获取2个日期相差的天数123456789mysql&gt; select datediff('2017-09-11 10:00:00','2017-09-08 00:00:00');+-------------------------------------------------------+| datediff('2017-09-11 10:00:00','2017-09-08 00:00:00') |+-------------------------------------------------------+| 3 |+-------------------------------------------------------+1 row in setmysql&gt; TIMEDIFF(expr1,expr2)，返回expr1-expr2的时间差123456789mysql&gt; select timediff('2017-09-11 10:00:00','2017-09-08 00:00:00');+-------------------------------------------------------+| timediff('2017-09-11 10:00:00','2017-09-08 00:00:00') |+-------------------------------------------------------+| 82:00:00 |+-------------------------------------------------------+1 row in setmysql&gt; TIMESTAMPDIFF(unit,datetime_expr1,datetime_expr2)返回指定unit的datetime_expr2 − datetime_expr1时间差unit可以是MICROSECOND (microseconds), SECOND, MINUTE, HOUR, DAY, WEEK, MONTH, QUARTER, or YEAR.123456789101112131415mysql&gt; select timestampdiff(DAY,'2017-09-11 10:00:00','2017-09-08 00:00:00');+----------------------------------------------------------------+| timestampdiff(DAY,'2017-09-11 10:00:00','2017-09-08 00:00:00') |+----------------------------------------------------------------+| -3 |+----------------------------------------------------------------+1 row in setmysql&gt; select timestampdiff(HOUR,'2017-09-11 10:00:00','2017-09-08 00:00:00');+-----------------------------------------------------------------+| timestampdiff(HOUR,'2017-09-11 10:00:00','2017-09-08 00:00:00') |+-----------------------------------------------------------------+| -82 |+-----------------------------------------------------------------+1 row in set 时间加减函数对日期进行加减操作，有很多方法可以使用，最简单的是直接使用interval1234567mysql&gt; select now(),now() + interval 3 DAY,now()+interval 1 Hour;+---------------------+------------------------+-----------------------+| now() | now() + interval 3 DAY | now()+interval 1 Hour |+---------------------+------------------------+-----------------------+| 2017-09-11 10:57:18 | 2017-09-14 10:57:18 | 2017-09-11 11:57:18 |+---------------------+------------------------+-----------------------+1 row in set 当然也可使用提供的函数 ADDDATE(date,INTERVAL expr unit), ADDDATE(expr,days)DATE_ADD(date,INTERVAL expr unit), DATE_SUB(date,INTERVAL expr unit) 1234567mysql&gt; select now(),date_add(now(),interval 1 Day),adddate(now(),interval 3 Hour);+---------------------+--------------------------------+--------------------------------+| now() | date_add(now(),interval 1 Day) | adddate(now(),interval 3 Hour) |+---------------------+--------------------------------+--------------------------------+| 2017-09-11 10:59:09 | 2017-09-12 10:59:09 | 2017-09-11 13:59:09 |+---------------------+--------------------------------+--------------------------------+1 row in set 更多日期、时间函数参考官方介绍: https://dev.mysql.com/doc/refman/5.7/en/date-and-time-functions.html 条件判断函数if if(expr,v1,v2)如果expr为真，则返回v1，为假，则返回v2123456789mysql&gt; select if(1&gt;0,'ok','no'),if(1=0,'ok','no');+-------------------+-------------------+| if(1&gt;0,'ok','no') | if(1=0,'ok','no') |+-------------------+-------------------+| ok | no |+-------------------+-------------------+1 row in setmysql&gt; ifnull ifnull(v1,v2)如果v1的值为null，则返回v2，如果v1不为null，则返回v1123456789mysql&gt; select ifnull(99,20),ifnull(NULL,99);+---------------+-----------------+| ifnull(99,20) | ifnull(NULL,99) |+---------------+-----------------+| 99 | 99 |+---------------+-----------------+1 row in setmysql&gt; case when 这里可以根据多个条件来判断，在不同的情况下，返回不同的值 123456789101112select s_id,s_name,s_gender, case when s_gender=0 then '男' when s_gender=1 then '女' end gender, s_birthday, s_hobby, c_idfrom t_student;]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>SQL</tag>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL-regexp]]></title>
    <url>%2F2017%2F09%2F09%2Fmysql-handbook-04%2F</url>
    <content type="text"><![CDATA[MySQL正则表达式 在前面，我们了解了like的使用，它可以做一些简单的匹配 在like中，我们使用%来代替任意个或多个字符，_表示任意单个字符 但在实际的应用场景中，我们可能还会需要更强大的匹配方式，比如“正则表达式”，这就需要使用regexp。 常用的正则表达式，更多的内容，大家可以百度下 我们就以前面的t_student表为例 查询学生姓路或乔的学生信息12345-- like select *from t_student where s_name like '路%' or s_name like '乔%'-- regexpselect *from t_student where s_name regexp '^(路|乔)' 查询名字是以美结尾的学生信息1select *from t_student where s_name regexp '美$' 查询学生爱好中，有吃肉的学生信息1select *from t_student where s_hobby regexp '吃肉' 查询学生姓乔或者名字中有美字的学生信息1select *from t_student where s_name regexp '(^乔)|美' 小结这里先整理这几个简单的例子，后续会再补充。 可以参考官方的文档练习：https://dev.mysql.com/doc/refman/5.7/en/regexp.html]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>SQL</tag>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL-分组排序]]></title>
    <url>%2F2017%2F09%2F09%2Fmysql-handbook-05%2F</url>
    <content type="text"><![CDATA[MySQL分组排序 使用过其他数据库的同学，一定知道那些好用的开窗函数，像什么rank() over(),sum() over() 等等，实现一些功能的时候很好用，但是呢，MySQL中并没有这些函数，那怎样实现这些功能呢？我们可以使用MySQL中的变量来实现这个功能。 我们先来看第一个类型的问题，关于排序的问题 排名就是按照指定的字段，给每一条记录分配一个行号（序号），作为他的排名在postgresql中可以使用像rank() over()这样的函数1234567select course_name, s_id, score, rank() over(order by score desc) rank_scorefrom t_score 但在MySQL中，就没这么方便了，我们需要使用变量，来模拟实现12345678910select course_name, s_id, score, -- 根据排序规则，每条记录增加1 @rn:=@rn+1 as rank_score -- 初始化变量@rn，从0开始from t_score cross join (select @rn:=0) xorder by score desc; 细心的同学，会发现，上面的排名会有些差别，以前2条记录为例，因为都是87，所以postgresql中排名都是1，而在MySQL中呢，依然是自增，一个1，一个2，那我们是否能让他也是2个1并列呢？ 当然可以，我们改一下SQL只要我们判断一下，当前记录的score和上一条记录的score是不是一样就可以了，那怎样才能获取上一条记录的score呢？就是增加一个变量来记录上一条记录的score12345678910111213select course_name, s_id, score, @pre pre_score, -- 判断当前score是否和上一条记录的score相等， -- 如果相等则使用和上一条一样的排名 if(@pre=score ,@rn:=@rn,@rn:=@rn+1) as rank_score, @pre:=score cur_score -- 使用pre来保存上一条记录的scorefrom t_score cross join (select @rn:=0,@pre:=null) xorder by score desc; 上面的排序还是有点儿问题，比如有2个第1之后，依然从第2开始，那我们能不能跳过直接从3开始呢？ 我们回想下，最开始他的排名其实就是3，只是我们上边把它变成了2，那我们再有一个和之前一样的变量就够了。 1234567891011select course_name, s_id, score, @pre pre_score, @rn_1:=@rn_1+1 rank_score_1, if(@pre=score ,@rn:=@rn,@rn:=@rn_1) as rank_score, @pre:=score cur_score from t_score cross join (select @rn:=0,@pre:=null,@rn_1:=0) xorder by score desc 我们使用@rn_1来正常记录排名，当当前记录和上一条记录的score不一样时，我们使用@rn_1的排名信息。 分组排序就是给每个分组中的数据，分别进行排名如果有类似rank() over()的函数12345678-- 在postgresql中select course_name, s_id, score, rank() over(partition by course_name order by score desc) rank_scorefrom t_score 但在MySQL中，就没这么方便了，我们需要使用变量，来模拟实现这里的思路和上面的思路一样，我们需要一个变量来保存上一条记录的课程名称，如果课程名称一样，则继续排名，如果不一样，则重新开始排名1234567891011set @rn:=0;set @pre_course:=null;select course_name, s_id, score, if(@pre_course=course_name,@rn:=@rn+1,@rn:=0), @pre_course:= course_name from t_score order by course_name,score desc;]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>SQL</tag>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SQL笔试题-MySQL练习题]]></title>
    <url>%2F2017%2F09%2F09%2Fdata-analyst-interview-sql-04%2F</url>
    <content type="text"><![CDATA[SQL笔试题 下面的SQL基于MySQL 下面整理些MySQL学习过程中，基本的练习题，题目来源于网上及个人总结。 测试数据12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970create table t_student( s_id int comment '学生ID', s_name varchar(20) comment '学生姓名', s_gender int comment '学生性别 0-男,1-女', s_birthday date comment '出生日期', s_hobby varchar(100) comment '爱好', c_id int comment '班级ID') comment '学生表';create table t_class( c_id int comment '班级ID', c_name varchar(20) comment '班级名称') comment '班级表';create table t_score( sc_id int comment '成绩ID', s_id int comment '学生ID', course_name varchar(20) comment '课程名称', score numeric(10,0) comment '成绩' ) comment '成绩表';insert into t_class values(901,'一班');insert into t_class values(902,'二班');insert into t_class values(903,'三班');insert into t_class values(905,'五班');insert into t_student values(101,'路飞',0,'1990-01-26','吃肉,睡觉',901);insert into t_student values(102,'娜美',1,'1995-10-05','足球,篮球',901);insert into t_student values(103,'乔巴',0,'1992-08-11','唱歌,吃肉',901);insert into t_student values(104,'鸣人',0,'1991-03-29','拉面,忍术',901);insert into t_student values(105,'卡卡西',1,'1989-05-10','看书,吃肉',902);insert into t_student values(106,'乌索普',1,'1988-02-02','跳舞,篮球',902);insert into t_student values(107,'乔峰',0,'1990-12-12','跑步,羽毛球',902);insert into t_student values(108,'段誉',0,'1990-12-13','吃肉,加班',903);insert into t_student values(109,'虚竹',1,'1991-01-22','看电影,旅行',903);insert into t_student values(110,'杨过',0,'2000-03-04','旅行',903);insert into t_student values(111,'令狐冲',0,'1997-03-04','喝酒',904);insert into t_score values(1,101,'数学',39);insert into t_score values(2,102,'数学',20);insert into t_score values(3,103,'数学',54);insert into t_score values(4,104,'数学',38);insert into t_score values(5,105,'数学',70);insert into t_score values(6,106,'数学',15);insert into t_score values(7,107,'数学',75);insert into t_score values(8,108,'数学',84);insert into t_score values(9,109,'数学',87);insert into t_score values(10,110,'数学',67);insert into t_score values(11,101,'语文',73);insert into t_score values(12,102,'语文',71);insert into t_score values(13,103,'语文',82);insert into t_score values(14,104,'语文',83);insert into t_score values(15,105,'语文',36);insert into t_score values(16,106,'语文',87);insert into t_score values(17,107,'语文',74);insert into t_score values(18,108,'语文',19);insert into t_score values(19,109,'语文',29);insert into t_score values(20,110,'语文',26);insert into t_score values(21,101,'英语',55);insert into t_score values(22,102,'英语',24);insert into t_score values(23,103,'英语',38);insert into t_score values(24,104,'英语',82);insert into t_score values(25,105,'英语',12);insert into t_score values(26,106,'英语',15);insert into t_score values(27,107,'英语',50);insert into t_score values(28,108,'英语',68);insert into t_score values(29,109,'英语',77);insert into t_score values(30,110,'英语',19); 查询所有课程分数都大于50分的学生信息12345678910111213141516select *from t_student where s_id in ( -- 按学生ID分组，看每个学生的最低分数是否大于50分 select s_id from t_score group by s_id having min(score)&gt;=50); 换另一种方式，实现上一题123456789101112select *from t_student where s_id not in ( -- 查询分数小于50分的学生ID select s_id from t_score where score &lt; 50) and s_id in ( -- 加上这个判断，是因为有的学生没有考试成绩 select s_id from t_score); 查询最少有2门课程都&gt;=60分的学生信息123456789101112131415161718select *from t_student where s_id in ( select s_id from t_score where score&gt;=60 group by s_id having count(1)&gt;=2); 查询每个学生的个人信息及班级信息及所有科目分数，按照班级ID升序排列，课程分数降序排列12345678910111213141516select a.*,b.c_name,c.course_name,c.scorefrom t_student ajoin t_class b on b.c_id = a.c_idjoin t_score c on c.s_id = a.s_idorder by a.c_id asc, c.score desc ; 查询每个学生的学生ID、学生姓名、班级名称、总分、平均分，按照班级名称升序、总分降序排列123456789101112131415161718192021222324select a.s_id, a.s_name, b.c_name, sum(c.score) total_score, avg(c.score) avg_scorefrom t_student ajoin t_class b on b.c_id = a.c_idjoin t_score c on c.s_id = a.s_idgroup by a.s_id, a.s_name, b.c_nameorder by b.c_name, total_score desc; 上一题，加上平均分大于60分1234567891011121314151617181920212223242526select a.s_id, a.s_name, b.c_name, sum(c.score) total_score, avg(c.score) avg_scorefrom t_student ajoin t_class b on b.c_id = a.c_idjoin t_score c on c.s_id = a.s_idgroup by a.s_id, a.s_name, b.c_namehaving avg_score &gt;= 60order by b.c_name, total_score desc; 查询数学成绩比语文成绩高的所有学生信息及数学、语文的成绩123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960-- 使用子查询select x.*, a.course_name course_math, a.score math_score, b.course_name course_language , b.score language_scorefrom t_student xjoin ( -- 所有学生的数学成绩 select * from t_score WHERE course_name = '数学') aon x.s_id = a.s_idjoin ( -- 所有学生的语文成绩 select * from t_score WHERE course_name = '语文') b on a.s_id = b.s_idand b.score &lt;= a.score;-- 2. 使用joinselect x.*, y.course_name course_math, y.score math_score, z.course_name course_language , z.score language_scorefrom t_student xjoin t_score yON x.s_id = y.s_idand course_name = '数学'join t_score zon z.course_name = '语文'and z.s_id = y.s_id and z.score &lt;= y.score; 查询英语和语文成绩都大于60的学生信息1234567891011121314151617select x.* from t_student xjoin ( select a.s_id from t_score a where a.score &gt; 60 and a.course_name in ('英语','语文') group by a.s_id having count(1) = 2) y on y.s_id=x.s_id; 查询每个学生的学生ID、学生姓名及平均分,按照平局分降序排列123456789101112131415select b.s_id, b.s_name, avg(a.score) avg_scorefrom t_score ajoin t_student b on b.s_id = a.s_idgroup by b.s_id, b.s_nameorder by avg_score desc 上一题，加上，平局分大于60分1234567891011121314151617select b.s_id, b.s_name, avg(a.score) avg_scorefrom t_score ajoin t_student b on b.s_id = a.s_idgroup by b.s_id, b.s_namehaving avg_score &gt; 60order by avg_score desc 上上一题，加上只查看平均分最高的学生信息1234567891011121314151617select b.s_id, b.s_name, avg(a.score) avg_scorefrom t_score ajoin t_student b on b.s_id = a.s_idgroup by b.s_id, b.s_nameorder by avg_score desclimit 1; 上上上一题，加上平局分第3高的学生信息1234567891011121314151617select b.s_id, b.s_name, avg(a.score) avg_scorefrom t_score ajoin t_student b on b.s_id = a.s_idgroup by b.s_id, b.s_nameorder by avg_score desclimit 1 offset 2; 换一种方式实现上一题12345678910111213141516171819202122232425select x.s_id, x.s_name, x.avg_score, @cur_rank := @cur_rank+1 as score_rankfrom ( select b.s_id, b.s_name, avg(a.score) avg_score from t_score a join t_student b on b.s_id = a.s_id group by b.s_id, b.s_name) xcross join ( select @cur_rank:=0)yorder by x.avg_score desc;]]></content>
      <categories>
        <category>笔试题</category>
      </categories>
      <tags>
        <tag>SQL</tag>
        <tag>笔试题</tag>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL-关联查询]]></title>
    <url>%2F2017%2F09%2F09%2Fmysql-handbook-03%2F</url>
    <content type="text"><![CDATA[MySQL关联查询 前面，我们介绍的都是单表查询（就是只从一张表中获取数据），而实际应用的时候，我们都会同时查询多张表，这里，我们就介绍下，多表关联查询的使用。 SQL join 用于根据两个或多个表中的列之间的关系，从这些表中查询数据 前置知识 主键（Primary Key）：可以唯一确定一条记录的字段，比如学生表中的学生ID，生活中我们的身份证号外键（Foreign Key）：指向另一张表的主键，比如学生表中的班级ID，班级ID是班级表中的主键，但在学生表中是外键 主键和外键可以在建表的时候指定，他可以在数据库层面，控制你的数据的完整性、一致性。 测试数据参考：http://yuguiyang.github.io/2017/09/09/mysql-handbook-01/ inner joininner join 可以简写为 join，结果集是两张表中 都存在的记录，是一个交集，详情参考上面的图片。比如：在学生表中，有一个班级ID，我们想根据班级ID，在班级表中找到班级信息1234567891011select *from t_student a -- 要关联查询的表join t_class b -- 使用什么字段去关联这两张表on a.c_id = b.c_id; left join左关联，以左边的表为主表，不管外键在右表中是否存在，左表的数据都会存在。比如学生表中，有这样一条记录，他的班级ID是904，但是班级表中并没有904的班级信息，所以，使用join的话是查不到这条记录的1234567891011-- 2. left join -- 学生表为主表，包含所有学生信息select *from t_student a left join t_class b on a.c_id = b.c_id; right join右关联，和做关联类似，但已右表为主表123456789101112-- 3. right join -- 班级表为主表，不管改班级是否有学生信息select *from t_student a right join t_class b on a.c_id = b.c_id; full outer join全关联，mysql没有full join 语法，我们可以通过使用union来实现123456789101112131415161718select *from t_student a left join t_class b on a.c_id = b.c_idUNIONselect *from t_student a right join t_class b on a.c_id = b.c_id; cross joincross join 是对2个表做笛卡尔积123select *from t_class a cross join t_class b order by a.c_id,b.c_id 小结关联查询的话，我们主要是选择好主表，然后找好表与表之间的关联关系，注意多对多、一对多的这种关系，验证号结果数据就行了。]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>SQL</tag>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL-中文排序]]></title>
    <url>%2F2017%2F09%2F09%2Fmysql-handbook-02%2F</url>
    <content type="text"><![CDATA[MySQL中文排序 测试数据参考：http://yuguiyang.github.io/2017/09/09/mysql-handbook-01/ 以前还真没有关注这个中文排序的问题，这里记录下。 一张学生表1select *from t_student; 我们根据s_name来排序1select *from t_student order by s_name; 这里的中文排序，是不对的，应该是由于字符集的问题，一般情况下，数据库中的编码都是使用UTF-8的，所以，对于中文会有问题。 从网上找到2中解决办法 create table的时候加上binary属性（经测试，不好用）注意下s_name字段，我们添加了binary属性12345678CREATE TABLE `t_student_test` ( `s_id` int(11) DEFAULT NULL COMMENT '学生ID', `s_name` varchar(20) binary DEFAULT NULL COMMENT '学生姓名', `s_gender` int(11) DEFAULT NULL COMMENT '学生性别 0-男,1-女', `s_birthday` date DEFAULT NULL COMMENT '出生日期', `s_hobby` varchar(100) DEFAULT NULL COMMENT '爱好', `c_id` int(11) DEFAULT NULL COMMENT '班级ID') ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT='学生表'; 这里，我试验是失败的，中文排序依然不对 在order by 后面，使用 convert函数1select *from t_student order by convert(s_name using gbk); 使用convert函数是可以的，没有问题]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>SQL</tag>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL-基本语法介绍]]></title>
    <url>%2F2017%2F09%2F09%2Fmysql-handbook-01%2F</url>
    <content type="text"><![CDATA[MySQL基本语法介绍 1. 什么是SQLSQL（Structured Query Language）结构化查询语言，通过SQL，我们就可以查询数据库中的数据，而数据再数据库中又是以表的形式保存的，所以SQL查询，主要就是对表进行查询。 SQL的语法就和学习英语的语法、汉语拼音一样，满足给定的套路，去使用就可以了。 当我们拿到了数据库的连接信息，连接到一个数据库上，我们就可以开始写SQL了。 2. Navicat的使用MySQL的客户端有很多，通常使用的，可能有Navicat，还有MySQL自带的workbench。Navicat是收费产品，但在网上可以找到XX版，workbench是免费的。 这里以Navicat为例，简单介绍下。 在这里，输入数据库地址、用户名、密码等等就行了。 这一个一个圆柱形的，就是一个数据库实例，下面那些电子表格图标的就是表，数据就存储在表中。 默认是不会看到表结构信息的，我们勾选下面的配置之后，就可以看到了 3. 基本语法数据准备12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970create table t_student( s_id int comment '学生ID', s_name varchar(20) comment '学生姓名', s_gender int comment '学生性别 0-男,1-女', s_birthday date comment '出生日期', s_hobby varchar(100) comment '爱好', c_id int comment '班级ID') comment '学生表';create table t_class( c_id int comment '班级ID', c_name varchar(20) comment '班级名称') comment '班级表';create table t_score( sc_id int comment '成绩ID', s_id int comment '学生ID', course_name varchar(20) comment '课程名称', score numeric(10,0) comment '成绩' ) comment '成绩表';insert into t_class values(901,'一班');insert into t_class values(902,'二班');insert into t_class values(903,'三班');insert into t_student values(101,'路飞',0,'1990-01-26','吃肉,睡觉',901);insert into t_student values(102,'娜美',1,'1995-10-05','足球,篮球',901);insert into t_student values(103,'乔巴',0,'1992-08-11','唱歌,吃肉',901);insert into t_student values(104,'鸣人',0,'1991-03-29','拉面,忍术',901);insert into t_student values(105,'卡卡西',1,'1989-05-10','看书,吃肉',902);insert into t_student values(106,'乌索普',1,'1988-02-02','跳舞,篮球',902);insert into t_student values(107,'乔峰',0,'1990-12-12','跑步,羽毛球',902);insert into t_student values(108,'段誉',0,'1990-12-13','吃肉,加班',903);insert into t_student values(109,'虚竹',1,'1991-01-22','看电影,旅行',903);insert into t_student values(110,'杨过',0,'2000-03-04','旅行',903);insert into t_score values(1,101,'数学',39);insert into t_score values(2,102,'数学',20);insert into t_score values(3,103,'数学',54);insert into t_score values(4,104,'数学',38);insert into t_score values(5,105,'数学',70);insert into t_score values(6,106,'数学',15);insert into t_score values(7,107,'数学',75);insert into t_score values(8,108,'数学',84);insert into t_score values(9,109,'数学',87);insert into t_score values(10,110,'数学',67);insert into t_score values(11,101,'语文',73);insert into t_score values(12,102,'语文',71);insert into t_score values(13,103,'语文',82);insert into t_score values(14,104,'语文',83);insert into t_score values(15,105,'语文',36);insert into t_score values(16,106,'语文',87);insert into t_score values(17,107,'语文',74);insert into t_score values(18,108,'语文',19);insert into t_score values(19,109,'语文',29);insert into t_score values(20,110,'语文',26);insert into t_score values(21,101,'英语',55);insert into t_score values(22,102,'英语',24);insert into t_score values(23,103,'英语',38);insert into t_score values(24,104,'英语',82);insert into t_score values(25,105,'英语',12);insert into t_score values(26,106,'英语',15);insert into t_score values(27,107,'英语',50);insert into t_score values(28,108,'英语',68);insert into t_score values(29,109,'英语',77);insert into t_score values(30,110,'英语',19); select下面，我们来看看，怎样查看一张表的数据；SQL的语法呢，就好比是一个公式，初学的话我们去套用就可以了。 SELECT 列名称 FROM 表名称或者SELECT * FROM 表名称 使用Navicat执行查询12-- 查看学生表数据，指定字段select s_id,s_name from t_student; 12-- 查看所有字段select *from t_student; 排序排序是很常用的功能，我们想要对结果集进行指定的排序，就要使用order by order by 字段名默认升序，可以使用desc降序排列 12-- 学生ID降序排列select *from t_student order by s_id desc; 多字段排序12-- 班级ID升序排列，班级ID一样的按学生ID降序排列select *from t_student order by c_id,s_id desc; limit 指定返回记录的数目 我们上面，都是查询一张表所有的数据，有的时候表的数据量很大，或者我们只想看看排名前3的数据，我们就可以使用limit12-- 学生ID降序排列,取前3条记录select *from t_student order by s_id desc limit 3; where前面，我们可以查看一张表的所有数据、做排序、然后只取前几行，实际使用时，一定会有这样的需求，比如我们只想看学生ID是105的记录，就需要使用where了，它可以对数据进行过滤。 SELECT 列名称 FROM 表名称 WHERE 列 运算符 值 12345678-- 查看学生ID是105的学生信息select *from t_student where s_id = 105;-- 查看学生ID不是105的其他学生信息select *from t_student where s_id &lt;&gt; 105 ;-- 查看学生ID在103和108之间的学生信息select *from t_student where s_id between 103 and 108; 这里还有一个操作符很常用，就是 in 和 not in。in 表示在多个值中存在，加上not则表示不存在12345-- 查看学生ID是103,105，,107的学生信息select *from t_student where s_id in (103,105,107);-- 查看学生ID不在102中的其他学生信息select *from t_student where s_id not in (102); like匹配字符串，像‘xxxx’一样 %： 表示任意个或多个字符_：表示任意单个字符 123-- 查看喜欢吃肉的学生信息select *from t_student where s_hobby like '吃肉%';select *from t_student where s_hobby like '%吃肉%'; and 和 or上面，我们都是一个单独的过滤条件，实际上，我们的会有各种各样的情况，需要同时满足多种过滤条件，这就用到了 and 和 or。 AND 和 OR 可在 WHERE 子语句中把两个或多个条件结合起来。如果第一个条件和第二个条件都成立，则 AND 运算符显示一条记录。如果第一个条件和第二个条件中只要有一个成立，则 OR 运算符显示一条记录。 12345-- 查看班级ID是901的所有男生信息select *from t_student where c_id=901 and s_gender=0;-- 查看班级ID是901或者s_id大于107的学生信息select *from t_student where c_id=901 or s_id &gt; 107;]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>SQL</tag>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[读书笔记-数据分析实战(3章)]]></title>
    <url>%2F2017%2F09%2F04%2Freading_notes_data_analysis_02%2F</url>
    <content type="text"><![CDATA[读书笔记 《数据分析实战》 从第3章开始，都是从一个实际问题出发，套用，前面的数据分析思路，来进行模拟分析。第3章的主题是“销售额为什么会减少？”：一款社交游戏本月的销售额相较于上月有所下滑，于是想调查下滑的原因，来提升销售额。 现状和预期现状肯定是当月销售额下降，预期肯定是保持上升，等于甚至高于上月销售额，这里的话，要确定销售额下降是不是一个问题，因为该社交游戏一直保持稳定增长，所以突然下滑，一定是不正常的， 是一个问题。 发现问题我们明确了现状和预期，需要从中，找出影响最大的因素。上面说到，有3种方法去发现问题： 观察数据大小 数据分解（指标拆解） 数据对比 这一步，也是一个根据经验来提出假设的过程，我们需要从宏观角度，找到可能影响销售额的因素。我感觉，这一步是数据分析切入的点，比较重要，如果这一步没有发现核心问题，那后面的数据收集和分析都会有问题。 书中，在这一步，提出的问题是“商业宣传上存在问题”，对了，这一步，还需要及时和其他部门去沟通，像这种市场推广、商业宣传，本身我们可能不知道，所以，假设后要去确认是否有这样的情况。 数据的收集和加工数据分析解决对策]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>数据分析</tag>
        <tag>读书笔记</tag>
        <tag>实例</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据分析案例-购物篮分析]]></title>
    <url>%2F2017%2F09%2F01%2Fdata-analyst-method-01%2F</url>
    <content type="text"><![CDATA[数据分析案例 说到数据分析、数据挖掘，我们首先想到的可能就是沃尔玛那个“啤酒与尿布”的故事，它告诉我们，世间万物都有着千丝万缕的联系。这其中使用的数据分析方法就是“关联分析”。 什么是购物篮分析购物篮分析（Market Basket Analysis），购物篮就是我们去超市使用的篮子，结账的时候，购物篮中所有的商品都会被一起结算。所谓的购物篮分析就是通过购物篮子所反应的信息来==研究顾客的购买行为== 关联分析要解决的问题是：一群用户购买了很多产品之后，哪些产品同时购买的几率比较高？买A产品的同时，买哪个产品的几率比较高 这里介绍完概念，暂时还没啥写的，后面再补充下怎样实现，这里会有一个Tableau的简单购物篮分析。 参考文章上文的部分理论知识，摘自下面的博客 一起大数据]]></content>
      <categories>
        <category>数据分析</category>
      </categories>
      <tags>
        <tag>数据分析</tag>
        <tag>购物篮分析</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[读书笔记-数据分析实战(1、2章)]]></title>
    <url>%2F2017%2F09%2F01%2Freading_notes_data_analysis_01%2F</url>
    <content type="text"><![CDATA[读书笔记 《数据分析实战》 1. 什么是数据科学家书中通过“什么是数据”和“数据在商业中的应用”，推导出数据科学家的定义。 人们通过观测数据来推测出某种因果关系，再用这种因果关系来预测未来或者控制原因以达到预期的结果。把从事这种工作的人成为数据科学家。– 书中摘录 上面的定义觉得不是很清晰，就百度上找了找： 数据科学家是指能采用科学方法、运用数据挖掘工具对复杂多量的数字、符号、文字、网址、音频或视频等信息进行数字化重现与认识，并能寻找新的数据洞察的工程师或专家(不同于统计学家或分析师)。一个优秀的数据科学家需要具备的素质有：懂数据采集、懂数学算法、懂数学软件、懂数据分析、懂预测分析、懂市场应用、懂决策分析等。– 百度百科 我觉得数据科学家就是对于数据相关的所有门类都有一个整体的认识，感觉是个“杂家”，精通算法、什么深度学习、机器学习、AI之类的都是信手拈来，对我就是神一样的存在了，努力吧，同学。 2. 3中类型的数据科学家书中将数据科学家分成了3类，主要从所在领域分类： 商业领域出身 统计学出身 工程领域出身 这应该也是数据科学家成长的3条路线，从不同的路线出发，最终殊途同归。当然，这3个领域需要综合，才称得上是合格的数据科学家。 书中的技能配图，可以瞻仰下 数据分析的5个流程书中，将数据分析分为5个步骤，看完后，感觉很靠谱，真的很实用，这里分享下 商业数据分析的目的是解决问题，要解决问题，需要使用统计分析、机器学习、数据挖掘等各种方法。 现状和预期首先我们要确认“什么才是数据分析中的问题”。比如，“某种商品销售额下降”，这是一个现象，但它是不是一个问题呢？如果，该产品不是公司主打商品，并且就要下架了，那销售额下降并不是一个问题，或者，该商品处于正常的波动，或是季节、市场环境的外部因素导致的，可能都不是一个问题；相反，如果该商品是公司主打商品，并且没有其他外部因素导致，那销售额下降就是个问题了。 这里记录下，其实，还需要确认下，销售额取数逻辑是否有问题，确保数据没有问题，并且要知道这个下降是怎么定义的，是和什么商品，或时间段对比发现下降的。 有对比，才会有差距，既然下降了，说明他心里一定有个预期，即现状和预期之间是有差距的 发现问题有了上面的“现状和预期”，我们需要区别”现象和问题“。像“销售额下降”，“顾客流失”，这都是一个现象，我们需要从中去发现问题 现象 前提 预期 是否有问题 销售额下降 销售额比例低 维持现状 无 销售额下降 销售额比例高 将销售额恢复到良好状态 有 销售额上升 广告费用高 降低广告费用 有 销售额上升 广告费用适当 维持现状 无 从3个角度发现问题发现问题的关键是思考并理解现状和预期之间的差距。那怎样发现、理解这个差距呢？ 观察数据大小首先考虑有哪些因素会导致这些差距，并明确这些因素的影响程度大小，即找到影响最大的因素。 将数据分解后观察指从多个角度观察发生的现象，分解出构成这种现象的因素。在分解的时候，必须遵循MECE原则： Mutually 相互性 Exclusive 排重性 Collectively 完整性 Exhaustive 全面性 我感觉这个很抽象，不是很理解，书上有一个例子，说的还不错，常用的拆分方法是因数分解，比如： 销售额=人均销售额*购买人数 拆解后，找到容易调控的因子，才方面后面去解决问题 将数据比较后观察指的是将发生问题是的数据和没发生问题时的数据相互比较，并找出问题出现的原因。比如，按时间对比，看看同比、环比（使用时间序列） 昨天和今天比较 上周和本周比较 同一个商业活动前、后比较 与竞争对手数据比较 公司内部服务之间利益比较 年龄段差异 性别差异 地域差异 3.3 数据收集和整理通过前面，对现状和预期的对比，发现影响最大的因素后，我们就需要开始收集数据，来验证问题。数据收集的话，还会涉及到怎样去采集数据，比如想要的数据，并没有保存下来。已保存下来的数据，通常会保存在文件、数据库或者是Hadoop（HDFS）中收集完数据，我们就需要对数据进行加工，变成我们后面分析需要的格式，比如使用SQL进行处理，或者Python、R进行整合；我们再加工数据的同时，为了方便我们后面的分析，可能还需要增加一下自定义的变量，比如一些标志位，像“已消费（1），未消费（0）”；或者是一些离散变量，类似于区间段： 消费金额较大用户（1） 消费金额一般用户（2） 消费金额较小用户（3） 3.4 数据分析书中把数据分析按目的，分为两大类：“决策支持和自动化、最优化”。其中，“决策支持”使用简单求和、交叉列表的方式分析，还会涉及预测模型；“自动化、最优化”则涉及机器学习、构建算法。 3.5 解决对策通过上面两种分析思路，我们需要针对分析的结果，来判断是否要采取对应的决策，不同的对策， 又会产生不同的沟通成本。]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>数据分析</tag>
        <tag>读书笔记</tag>
        <tag>实例</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SQL笔试题-连续登录天数]]></title>
    <url>%2F2017%2F08%2F31%2Fdata-analyst-interview-sql-03%2F</url>
    <content type="text"><![CDATA[SQL笔试题 下面的SQL基于PostgreSQL 1.用户连续登录天数背景描述现在我们有一张用户登录日志表，记录用户每天的登录时间，我们想要统计一下，用户每次连续登录的开始日期和结束日期，以及连续登录天数。 用户ID 登录日期 1001 2017-01-01 1001 2017-01-02 1001 2017-01-04 1001 2017-01-06 1002 2017-01-02 1002 2017-01-03 同学们先思考下，整理下思路，如果没有思路或者某几个点不了解，就可以继续往下看了。 测试数据1234567891011121314151617181920212223242526272829303132333435363738CREATE TABLE interview.tm_login_log( user_id integer, login_date date)WITH ( OIDS=FALSE);-- 这里的数据是最简化的情况，每个用户每天只有一条登录信息，insert into interview.tm_login_log values(1001,'2017-01-01');insert into interview.tm_login_log values(1001,'2017-01-02');insert into interview.tm_login_log values(1001,'2017-01-04');insert into interview.tm_login_log values(1001,'2017-01-05');insert into interview.tm_login_log values(1001,'2017-01-06');insert into interview.tm_login_log values(1001,'2017-01-07');insert into interview.tm_login_log values(1001,'2017-01-08');insert into interview.tm_login_log values(1001,'2017-01-09');insert into interview.tm_login_log values(1001,'2017-01-10');insert into interview.tm_login_log values(1001,'2017-01-12');insert into interview.tm_login_log values(1001,'2017-01-13');insert into interview.tm_login_log values(1001,'2017-01-15');insert into interview.tm_login_log values(1001,'2017-01-16');insert into interview.tm_login_log values(1002,'2017-01-01');insert into interview.tm_login_log values(1002,'2017-01-02');insert into interview.tm_login_log values(1002,'2017-01-03');insert into interview.tm_login_log values(1002,'2017-01-04');insert into interview.tm_login_log values(1002,'2017-01-05');insert into interview.tm_login_log values(1002,'2017-01-06');insert into interview.tm_login_log values(1002,'2017-01-07');insert into interview.tm_login_log values(1002,'2017-01-08');insert into interview.tm_login_log values(1002,'2017-01-09');insert into interview.tm_login_log values(1002,'2017-01-10');insert into interview.tm_login_log values(1002,'2017-01-11');insert into interview.tm_login_log values(1002,'2017-01-12');insert into interview.tm_login_log values(1002,'2017-01-13');insert into interview.tm_login_log values(1002,'2017-01-16');insert into interview.tm_login_log values(1002,'2017-01-17'); 步骤拆解我们首先要思考，怎样才算连续登录呢？就是1号登录，2号也登录了，这样就连续2天登录，那我们怎么知道2号他有没有登录呢？一种思路是根据排序来判断：我们来根据日期来排个名1234567select user_id, login_date, row_number() over(partition by user_id order by login_date) day_rankfrom interview.tm_login_log; 现在，我们根据用户ID，对他的登录日期做了排序，但是我们还是没有办法知道，他是不是连续的。我们根据这个排序再思考一下，对于一个用户来说，他的登录日期排序已经是连续的了，如果登录日期也是个数字，那我们根据每行的差值，就可以判断登录日期是否连续了。我们换个角度，我们找一个起始日期，来计算一个相差的天数，用它去和排序相对比，就可以了。12345678select user_id, login_date, date_part('day',login_date::timestamp - timestamp'2017-01-01') day_interval, -- 间隔天数 row_number() over(partition by user_id order by login_date) day_rank -- 日期排序from interview.tm_login_log; 我们观察下数据，因为日期排序是连续的，我们统计的间隔天数都是一个起始日期，所以，如果登录日期是连续的，那么，排序-间隔天数的差值也应该是一样的 12345678910111213select user_id, login_date, date_part('day',login_date::timestamp - timestamp'2017-01-01') day_interval, -- 间隔天数 row_number() over(partition by user_id order by login_date) day_rank, -- 日期排序 ( row_number() over(partition by user_id order by login_date) ) - ( date_part('day',login_date::timestamp - timestamp'2017-01-01') ) diff_valuefrom interview.tm_login_log; 差值一样的记录，就是连续登录的日期 好了，连续登录的判断标准，我们已经确定了，下面就是把题目中要的数据查出来即可1234567891011121314151617181920212223select user_id, --diff_value, --差值 min(login_date) start_date, --开始日期 max(login_date) end_date, --结束日期 count(1) running_days --连续登录天数from ( select user_id, login_date, date_part('day',login_date::timestamp - timestamp'2017-01-01') day_interval, -- 间隔天数 row_number() over(partition by user_id order by login_date) day_rank, -- 日期排序 ( row_number() over(partition by user_id order by login_date) ) - ( date_part('day',login_date::timestamp - timestamp'2017-01-01') ) diff_value from interview.tm_login_log) basegroup by user_id,diff_valueorder by user_id,start_date 拓展：获取用户最大的连续登录天数及开始日期和结束日期123456789101112131415161718192021222324252627282930313233with tmp as (select user_id, diff_value, --差值 min(login_date) start_date, --开始日期 max(login_date) end_date, --结束日期 count(1) running_days --连续登录天数from ( select user_id, login_date, date_part('day',login_date::timestamp - timestamp'2017-01-01') day_interval, -- 间隔天数 row_number() over(partition by user_id order by login_date) day_rank, -- 日期排序 ( row_number() over(partition by user_id order by login_date) ) - ( date_part('day',login_date::timestamp - timestamp'2017-01-01') ) diff_value from interview.tm_login_log) basegroup by user_id,diff_value) select a.user_id,a.start_date,a.end_date,a.running_daysfrom tmp ajoin ( select user_id,max(running_days) running_days from tmp group by user_id) b on a.user_id = b.user_idand a.running_days = b.running_days; 连续5天登录用户这里补充另一个类似的问题，这里，我们想看连续登录5天的用户，使用上面的方法可以实现，这里介绍一个更快的方法：是使用一个函数123456789101112向前取n位lag(value anyelement [, offset integer [, default anyelement ]])select *from ( select a.user_id, a.login_date, --5天前的登录日期 lag(a.login_date,4) over(partition by a.user_id order by a.login_date) pre_five_day from interview.tm_login_log a )xwhere date_part('day',x.login_date::timestamp - pre_five_day::timestamp)=4 这样取连续登录的话，比较方便 思考题：连续7天未登录用户这里留一个类似的小问题，大家自行练习下 小结我们简单整理下思路，上面的例子，我认为主要是一个思路的介绍，核心就是我们要找到一个判断连续的方法，找到方法后，SQL自然就一步一步想出来了。上面只是一种思路，一定还有更优的解法，欢迎大家反馈分享。]]></content>
      <categories>
        <category>笔试题</category>
      </categories>
      <tags>
        <tag>SQL</tag>
        <tag>笔试题</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SQL笔试题-行转列]]></title>
    <url>%2F2017%2F08%2F28%2Fdata-analyst-interview-sql-02%2F</url>
    <content type="text"><![CDATA[SQL笔试题 下面的SQL基于PostgreSQL 1. 行转列背景我们写SQL的时候，经常会遇到一些列转行、行转列的情况，有的时候是为了展现需要，有的时候是代码里就得这样转一下。总之嘞，得掌握这个技巧。下面就开始我们的练习。 测试数据1234567891011121314151617181920CREATE TABLE interview.tm_score( stu_name character varying(20), -- 学生名称 course_name character varying(20), -- 课程名称 score numeric(10,0) -- 分数)WITH ( OIDS=FALSE);-- 初始化数据insert into interview.tm_score values('路飞','数学',100);insert into interview.tm_score values('路飞','语文',62);insert into interview.tm_score values('路飞','英语',98);insert into interview.tm_score values('索隆','数学',40);insert into interview.tm_score values('索隆','语文',57);insert into interview.tm_score values('索隆','英语',40);insert into interview.tm_score values('娜美','数学',42);insert into interview.tm_score values('娜美','语文',44);insert into interview.tm_score values('娜美','英语',28); 我们先来思考第一个问题：我们怎样可以将课程变成列呢，类似交叉表那样？最容易想到的方法，就是使用case when了 case when1234567891011select stu_name, max(case course_name when '数学' then score else 0 end) as "数学", max(case course_name when '语文' then score else 0 end) as "语文", max(case course_name when '英语' then score else 0 end) as "英语" from interview.tm_scoregroup by stu_name; crosstab在新版本的PostgreSQL中有一个extension，可以方便的实现行转列我们需要先安装这个扩展，我看了下，PostgreSQL8.3以后的版本都可以安装1create extension tablefunc 官网地址：https://www.postgresql.org/docs/9.5/static/tablefunc.html 安装完后，会有这么几个函数 我们可以使用crosstab来实现上面的行转列123select *from crosstab( 'select stu_name,course_name,score from interview.tm_score') as ct(stu_name varchar(20) ,"数学" numeric(10,0),"语文" numeric(10,0), "英语" numeric(10,0)) 结果也是一样的，我们传入一个SQL，SQL里面返回3列（这3列都是默认处理的，第一列是主字段，第2列是要拆成列的字段，第3列是要显示的值），最后因为返回值是record，所以我们要定义一下类型。 这里，顺便看看这个函数的用法 要转成列的字段有Null是这样一种情况：不是所有的同学都有3门课程的分数我们删掉了几条记录来模拟 这时候使用crosstab，结果会有问题 数据会自动从第一列开始，导致错误的数据12345-- crosstab(text source_sql, text category_sql)select *from crosstab( 'select stu_name,course_name,score from interview.tm_score','select distinct course_name from interview.tm_score') as ct(stu_name varchar(20) ,"数学" numeric(10,0),"语文" numeric(10,0), "英语" numeric(10,0)) 这时候，数据就对了 source_sql 多于3列这种情况是，我们查询的结果不单单有上面说的3列，可能还有其他字段，比如，我们可以在上面的测试数据上加一个班级列我们同样也是使用上面的方式解决 12345678alter table interview.tm_score add column stu_class varchar(10);update interview.tm_score set stu_class='一班' where stu_name in ('路飞','索隆');update interview.tm_score set stu_class='二班' where stu_name not in ('路飞','索隆');select *from crosstab( 'select stu_name,stu_class,course_name,score from interview.tm_score','select distinct course_name from interview.tm_score') as ct(stu_name varchar(20) ,stu_class varchar(10),"数学" numeric(10,0),"语文" numeric(10,0), "英语" numeric(10,0)) 这里我们六个思考题，有这样一组数据： 我们想查询出这样格式的数据 大家可以练习下这个SQL该怎么写 列转行我们可以把行转成列，那要怎样把列转成行呢？ union all最简单的方法是直接union all,既然要放到一列里面，那字段类型肯定要一样，所以直接根据不同字段去union all 就好了 12345select stu_name,"数学" from xxxunion all select stu_name,"语文" from xxxunion allselect stu_name,"英语" from xxx 小结这里简单介绍了几种常见的处理方法，实际使用中，一定还有更好地方法、或一些特殊的问题，欢迎大家分享、反馈。]]></content>
      <categories>
        <category>笔试题</category>
      </categories>
      <tags>
        <tag>SQL</tag>
        <tag>笔试题</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SQL笔试题-累计值（月累计、年累计）]]></title>
    <url>%2F2017%2F08%2F28%2Fdata-analyst-interview-sql-01%2F</url>
    <content type="text"><![CDATA[SQL笔试题 下面的SQL基于PostgreSQL 1. 累计值（月累计、年累计）背景描述比如说，我们有这样一份数据,记录的是图书每天的销量情况： 日期 图书名称 销量 2017-01-01 解忧杂货店 90 2017-01-03 解忧杂货店 50 2017-01-05 解忧杂货店 100 2017-01-01 雪落香杉树 100 2017-01-03 雪落香杉树 44 2017-01-04 雪落香杉树 99 现在，我们要统计每本书，当月的累计销量？即1号是1号的销量，2号是1号+2号当天的销量（注意：这里2号当天虽然没有销量，但是应该为1号的90+2号的0，为90）。大家先思考下，如果可以很快解答，就不需要接着读啦，有疑问的同学可以继续往下看。 测试数据123456789101112131415161718192021222324252627282930313233343536373839-- 图书的销量表CREATE TABLE interview.tm_book_sales( calendar_date date, -- 日期 book_name character varying(100), -- 图书名称 sales numeric(10,0) -- 销量)WITH ( OIDS=FALSE);-- 测试数据insert into tm_book_sales values('2017-01-01','解忧杂货店',56);insert into tm_book_sales values('2017-01-02','解忧杂货店',100);insert into tm_book_sales values('2017-01-03','解忧杂货店',70);insert into tm_book_sales values('2017-01-06','解忧杂货店',11);insert into tm_book_sales values('2017-01-07','解忧杂货店',65);insert into tm_book_sales values('2017-01-08','解忧杂货店',9);insert into tm_book_sales values('2017-01-09','解忧杂货店',30);insert into tm_book_sales values('2017-01-10','解忧杂货店',56);insert into tm_book_sales values('2017-01-01','雪落香杉树',18);insert into tm_book_sales values('2017-01-02','雪落香杉树',40);insert into tm_book_sales values('2017-01-03','雪落香杉树',2);insert into tm_book_sales values('2017-01-04','雪落香杉树',22);insert into tm_book_sales values('2017-01-05','雪落香杉树',48);insert into tm_book_sales values('2017-01-07','雪落香杉树',71);insert into tm_book_sales values('2017-01-09','雪落香杉树',73);insert into tm_book_sales values('2017-01-10','雪落香杉树',37);insert into tm_book_sales values('2017-02-03','解忧杂货店',5);insert into tm_book_sales values('2017-02-05','解忧杂货店',46);insert into tm_book_sales values('2017-02-06','解忧杂货店',35);insert into tm_book_sales values('2017-02-07','解忧杂货店',10);insert into tm_book_sales values('2017-02-09','解忧杂货店',30);insert into tm_book_sales values('2017-02-10','解忧杂货店',12);insert into tm_book_sales values('2017-02-13','解忧杂货店',43);insert into tm_book_sales values('2017-02-01','雪落香杉树',10);insert into tm_book_sales values('2017-02-04','雪落香杉树',78);insert into tm_book_sales values('2017-02-10','雪落香杉树',50);insert into tm_book_sales values('2017-02-20','雪落香杉树',93); 现在呢，我们有了图书每天的销量数据，下面，我们思考1个问题：我想要统计每本图书的当月累计销量，应该怎么做呢？ 如果只是单纯的统计每本书每个月的销量，熟悉SQL的同学，一定可以很快想到12345678910111213select to_char(calendar_date,'yyyy-mm') month_name, book_name, sum(sales) from interview.tm_book_sales group by to_char(calendar_date,'yyyy-mm'), book_nameorder by book_name, to_char(calendar_date,'yyyy-mm'); 下面，我们来想下，这个月累计怎么做？月累计值，其实就是当天的销量再加上当天之前的销量 自关联通过 interview.tm_book_sales 表，我们可以获取每一天的销量，那要怎样获取每天历史的销量呢？最简单的方式就是自关联了。其实就是自己和自己去关联，来获取历史的销量123456789101112131415161718192021222324select t_today.calendar_date, t_today.book_name, sum(t_his.sales) sales_mtdfrom interview.tm_book_sales t_todayleft join interview.tm_book_sales t_hison -- 图书名称相等 t_his.book_name = t_today.book_name and -- 月份相等，只统计当月 to_char(t_his.calendar_date,'yyyy-mm') = to_char(t_today.calendar_date,'yyyy-mm')and -- 获取当天之前的历史日期 t_his.calendar_date &lt;= t_today.calendar_dategroup by t_today.calendar_date, t_today.book_nameorder by t_today.book_name, t_today.calendar_date; 好了，上面，我们通过自关联，获取了每本图书的月累计销量，不要太高兴，我们观察下，就会发现些问题。我们看看日期，就会发现，有些日期是没有销量的，比如：《解忧杂货店》2017-01-04，2017-01-05 就没有销量，但实际上，如果是累计值得花，他是应该有数据的，因为1号、2号、3号都有数据，就算4号当天没有销量，月累计也应该要算上前3天的销量，所以我们的SQL并不严谨，还得修改。 补全没有销量的日期我们需要想办法补全缺失的日期，如果，t_today里面含有每一天每本书的数据就好了，这就要我们手动构造一个了。123456789101112select t_day.calendar_date, t_book.book_namefrom -- 日期维度表，就是存放每一天 base.dm_calendar t_daycross join -- 所有的图书信息 (select distinct book_name from interview.tm_book_sales) t_bookwhere t_day.month_id=201701; 日期维度表的话，其实是数仓中必备的地基础维度中的一个，她里面就是存放了每一天的数据，和其他一些我们会常用的字段，后面写一篇文章详细介绍下。我们通过笛卡尔积，生成了一张包含每一天每本的图书的一个全维度表。1234567891011121314151617181920212223242526272829303132333435363738394041with t_dim as ( select t_day.calendar_date, t_book.book_name from base.dm_calendar t_day cross join (select distinct book_name from interview.tm_book_sales) t_book where t_day.month_id=201701)select t_dim.calendar_date, t_dim.book_name, sum(t_his.sales) sales_mtdfrom t_dimleft join interview.tm_book_sales t_todayon t_today.calendar_date = t_dim.calendar_dateand t_today.book_name = t_dim.book_nameleft join interview.tm_book_sales t_hison -- 图书名称相等 t_his.book_name = t_dim.book_name and -- 月份相等，只统计当月 to_char(t_his.calendar_date,'yyyy-mm') = to_char(t_dim.calendar_date,'yyyy-mm')and -- 获取当天之前的历史日期 t_his.calendar_date &lt;= t_dim.calendar_dategroup by t_dim.calendar_date, t_dim.book_nameorder by t_dim.book_name, t_dim.calendar_date; 好啦，补全了日期信息后，我们的月累计算是完成了，手工。 总结简单总结下，通过上面的例子，我们要掌握什么呢？首先是对业务的理解，比如上面的月累计的统计方法；然后根据统计方法，使用SQL去实现，一步步完善；还有对日期维度表的一个综合使用。年累计的实现也是一样的，同学们可以自行练习下，有问题可以反馈。]]></content>
      <categories>
        <category>笔试题</category>
      </categories>
      <tags>
        <tag>SQL</tag>
        <tag>笔试题</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[matplotlib手册(9) - 绘制动画]]></title>
    <url>%2F2017%2F08%2F17%2Fmatplotlib-base-flash-09%2F</url>
    <content type="text"><![CDATA[matplotlib手册(9) 绘制动画 前面，我们介绍了很多绘图的方法，matplotlib不单单可以绘制静态的图，还可以制作动态的图，下面，我们就来学习下。 我们主要参考matplotlib官网的例子http://matplotlib.org/api/animation_api.html 创建动画最简单的方式，就是使用Animation的子类,就是下面的这2个 1. FuncAnimation函数介绍及主要参数1234567891011class matplotlib.animation.FuncAnimation(fig, func, frames=None, init_func=None, fargs=None, save_count=None, **kwargs)fig : matplotlib.figure.Figurefunc : callableframes : iterable, int, generator function, or None, optionalinit_func : callable, optionalfargs : tuple or None, optionalinterval : number, optionalrepeat_delay : number, optionalrepeat : bool, optional 小栗子1234567891011121314151617181920212223242526272829# -*- coding: utf-8 -*-"""Created on Thu Aug 17 18:19:08 2017@author: yuguiyang"""import numpy as np import matplotlib.pyplot as plt import matplotlib.animation as animation from datetime import datetime fig,axes = plt.subplots() axes.plot(np.random.rand(10)) #重新绘制图形def update_line(data): print(datetime.now(),'--',data) #清空当前轴 plt.cla() #重新绘图 axes.plot(np.random.rand(10))#传入的fig中，调用update_line函数，将range(3)作为参数传给update_line，1秒调用一次ani = animation.FuncAnimation(fig, update_line, 3, interval=1000) plt.show() 上面的代码，我们定义了一个函数update_line，他会清空axes，并重新绘图；FuncAnimation会每个1秒调用一次这个函数 这里记录一个小问题，暂时还没有解决 frames 参数的问题上面的例子里，我们给的是一个常量3，按照官方的介绍，是按照range(3),来一次传给函数的，但实际测试下来，发现他的调用会有问题。我们看下上面的那个输出 刚刚发现了导致这个问题的原因，注意看这个：123init_func : callable, optional A function used to draw a clear frame. If not given, the results of drawing from the first item in the frames sequence will be used. This function will be called once before the first frame. 上面，因为我们没有指定初始化函数，所以导致，会调用一次update_line，用它返回值作为初始状态，我们改下脚本再看123456def init(): print('init') #清空当前轴 plt.cla() ani = animation.FuncAnimation(fig, update_line, 3, repeat=False, interval=3000,init_func=init) 这回输出就正常了， repeat、repeat_delay这2个参数一般会配合使用，repeat默认是true，所以上面的例子会一直循环下去，如果我们改为false,第一次循环完之后就会停止。 2. ArtistAnimation12345class matplotlib.animation.ArtistAnimation(fig, artists, *args, **kwargs)artists : list Each list entry a collection of artists that represent what needs to be enabled on each frame. These will be disabled for other frames. 使用起来和上面的差不多，这里不会调用函数，而是传入一个list，123456789101112131415import numpy as np import matplotlib.pyplot as plt import matplotlib.animation as animation fig,axes = plt.subplots() ims= []for i in range(5): ims.append(axes.plot(np.random.rand(10)))im_ani = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=3000, blit=True)print(ims)plt.show()]]></content>
      <categories>
        <category>数据可视化-Python&amp;R</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>数据可视化</tag>
        <tag>matplotlib</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[最新行政区信息获取]]></title>
    <url>%2F2017%2F08%2F14%2Fthe-newest-area-info-01%2F</url>
    <content type="text"><![CDATA[这是之前记录的，这里顺便分享下。 之前想要获取官方的省市区的代码code，就找了下。 官方地址：http://www.stats.gov.cn/tjsj/tjbz/xzqhdm/ 我们可以直接将数据复制到Excel中，简单处理下，导入到数据库中 里面会有换行，先去个重，然后trim一下，再分列就可以了 最后，我们可以将数据组织成我们想要的维度表格式 ————–update at 2017-08-15 上面呢，我是直接在Excel里面生成insert脚本插入数据库的，但是目前的表使用起来应该不是很方便，这里我们改造下。 这个区域信息呢，是很常用的一张维度表，通常他可能会是这个样子的123456789101112131415CREATE TABLE base.dm_area( area_id integer, area_name character varying(50), province_id integer, province_name character varying(50), city_id integer, city_name character varying(50), country_id integer, country_name character varying(50), flevel integer)WITH ( OIDS=FALSE); 这里我们就简单处理下，变成这种格式。 其实一开始的时候，我们可以通过数据的格式区分他是省份、城市、还是区县，下面我们用的是一个套路 主要是观察法，因为这个code都是有规律的，所以我们处理起来方便很多 code一共是6位，前两位是省份、中间2位是城市，后2位是区县1select *from public.b_area where area_id||'' like '00' 下面，我们来初始化数据12345678910111213141516171819202122232425262728293031323334353637INSERT INTO base.dm_area( area_id, area_name)select *from public.b_area; -- 初始化flevel 1:省份,2:城市,3:区县update base.dm_area set flevel=1 where area_id||'' like '00';update base.dm_area set flevel=2 where area_id||'' like '' and flevel is null;update base.dm_area set flevel=3 where flevel is null;-- 更新省份信息update base.dm_area a set province_id = b.area_id, province_name = b.area_namefrom base.dm_area bwhere left(a.area_id||'',2)=left(b.area_id||'',2) and b.flevel=1;-- 更新城市信息update base.dm_area a set city_id = c.area_id, city_name = c.area_name from base.dm_area c where left(a.area_id||'',4)=left(c.area_id||'',4) and c.flevel=2;-- 更新区县信息update base.dm_area a set country_id = area_id, country_name = area_name where a.flevel=3; 到这里，flevel=3的数据已经没有问题了，再对省份、城市做些优化就行了12345678910111213-- 补全数据update base.dm_area set city_id=-area_id,city_name=area_name||'XT', country_id=-area_id,country_name=area_name||'XT'where flevel=1;update base.dm_area set country_id=-area_id,country_name=area_name||'XT'where flevel=2; 好了，我们就处理好这个区域维度了，正常使用的话，估计就用flevel=3的就够了]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[爬虫小实例学习篇-猫眼电影]]></title>
    <url>%2F2017%2F08%2F09%2Fcrawler-demo-01%2F</url>
    <content type="text"><![CDATA[这里参考了论坛里一位同学分享的博客：猫眼电影TOP100爬取练习，感谢分享。 学习要从模仿开始，学习了上面的博客之后，自己做下练习，正好最近看了selenium，就用了这个。 原作者的正则用的太溜了，等后面有时间再研究下，这里就简单的使用CSS Selector来实现了。 原文代码很精彩，我这个代码就粗糙很多了，先来个初始版，后面再慢慢优化。 大体思路和Python基础（7）- Selenium使用 里面的豆瓣读书例子差不多， 代码（2017-08-09版）123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123import csvfrom selenium import webdriverfrom selenium.webdriver.common.by import Byfrom selenium.webdriver.support.ui import WebDriverWaitfrom selenium.webdriver.support import expected_conditions as ECfrom selenium.common.exceptions import TimeoutException#打开浏览器browser = webdriver.Firefox()#设置等待时长，最长等待10swait = WebDriverWait(browser,10)#定义电影排名comment_index = 0#定义一个movieclass Movie: __movie_id = 0 __movie_name = '' __movie_star = '' __movie_releasetime = '' __movie_score = '' def __init__(self , movie_id,movie_name,movie_star,movie_releasetime,movie_score): self.__movie_id = movie_id self.__movie_name = movie_name self.__movie_star = movie_star self.__movie_releasetime = movie_releasetime self.__movie_score = movie_score def show(self): print('影片排名: ', self.__movie_id) print('影片名称: ', self.__movie_name) print(self.__movie_star) print(self.__movie_releasetime) print('影片评分', self.__movie_score) print('') def simple_list(self): return [self.__movie_id, self.__movie_name, self.__movie_star, self.__movie_releasetime, self.__movie_score] def save2csv(movie_list): with open('movie.csv', 'a', newline='',encoding='utf-8') as csvfile: csv_writer = csv.writer(csvfile) for m in movie_list: csv_writer.writerow(m.simple_list()) csvfile.close() def main(): #打开URL browser.get('http://maoyan.com/board/4') #输出浏览器标题 print('browser title: ',browser.title) #数据更新信息 p_update_info = wait.until(EC.presence_of_element_located((By.CSS_SELECTOR,'div.main p.update-time'))) print('更新信息: ',p_update_info.text) #输出当前页信息 show_current_page() def show_current_page(): print('-----------------------------------') print('current url: ',browser.current_url) #获取当前页信息 div_page = wait.until(EC.presence_of_element_located((By.CSS_SELECTOR,'div.pager-main li.active'))) print('current page: ',div_page.text) #当前页总数量 div_items = wait.until(EC.presence_of_all_elements_located((By.CSS_SELECTOR,'div.main div.board-item-main div.board-item-content'))) print('total count: ',len(div_items)) movie_list = [] #结果集有很多结果，我们获取 for item in div_items: #调用全局变量 global comment_index comment_index += 1 #获取我们需要的信息 p_name = item.find_element_by_css_selector('div.movie-item-info p.name') p_star = item.find_element_by_css_selector('div.movie-item-info p.star') p_releasetime = item.find_element_by_css_selector('div.movie-item-info p.releasetime') p_score_integer = item.find_element_by_css_selector('div.movie-item-number p.score i.integer') p_score_fraction = item.find_element_by_css_selector('div.movie-item-number p.score i.fraction') #初始化movie对象 m = Movie(comment_index , p_name.text , p_star.text, p_releasetime.text, p_score_integer.text+p_score_fraction.text) movie_list.append(m) save2csv(movie_list) #获取下一页 show_next_page()def show_next_page(): try: #获取下一页的标签 #最后1页，没有下一页标签 a_next = wait.until(EC.presence_of_element_located((By.PARTIAL_LINK_TEXT,'下一页'))) a_next.click() show_current_page() except TimeoutException: #找不到下一页 print('get all movies.') #也有可能真是网络异常 finally: browser.quit() if __name__=='__main__': main() 这里就简单记录遇到的一些问题和后面需要优化的地方： 获取影片信息的时候，数据没有清洗好，像这个“主演”，“上映时间”还没有剔除掉；那个地点也可以拆分出来单独一个字段 csv编码问题，一开始默认使用gbk（在Windows下开发的），会报错，说是有异常的字符无法保存，改为UTF-8后，就可以了，但是使用CSV打开前，先用notepad++转了编码，才用CSV打开 使用正则去获取元素 4.异常问题的处理]]></content>
      <categories>
        <category>Python-爬虫</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>爬虫</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[numpy手册(1)-ndarray]]></title>
    <url>%2F2017%2F08%2F02%2Fnumpy-handbook-01%2F</url>
    <content type="text"><![CDATA[前面我们算是简单入门了Pandas，numpy也是数据分析中常用的，这里我们也来简单学习下。 1.numpy基本介绍numpy是Python的一种开源数值计算扩展，这种工具可以用来存储和处理大型矩阵。一个用Python实现的科学计算包。from 百度百科 numpy有2种基本对象，1ndarray（N-dimensional array object）和 ufunc（universal function object） ndarray是存储单一数据类型的多维数组，ufunc是能够对数组进行处理的函数。 2.ndarray我们先来看看这个数组首先，我们得引入numpy1import numpy as np 2.1 创建数组初始化的话有很多方式：Array creation routines我们可以直接使用list来初始化，array有很多的属性，比如大小，维度，元素个数123456789import numpy as npa = np.array([1,2,3])b = np.array([4,5,6])c = np.array([[1,2,3],[4,5,6],[7,8,9]])print(a,type(a),',shape:',a.shape,',ndim:',a.ndim,',size:',a.size)print(b,type(b),',shape:',b.shape,',ndim:',b.ndim,',size:',b.size)print(c,type(c),',shape:',c.shape,',ndim:',c.ndim,',size:',c.size) 这里呢，我们定义了一维数组和二维数组，比如c，是3行3列的2维数组，元素个数是9个1numpy.array(object, dtype=None, copy=True, order='K', subok=False, ndmin=0) 这里，我们再说下这个shape，这个属性可以修改123456789#原来是4行3列c = np.array([[1,2,3],[4,5,6],[7,8,9],[0,0,7]])print(c)#我们改为3行4列c.shape=(3,4)print(c)#改为2行6列c.shape=(2,6)print(c) 这里需要注意下，如果某个轴的元素为-1，将根据数组元素的个数，自动计算长度1234c.shape=(1,-1)print(c)c.shape=(-1,1)print(c) 这里的shape是改变原来的数组，另一个method，可以创建一个改变shape的新数组，而原数组保持不变12345c = np.array([[1,2,3],[4,5,6],[7,8,9],[0,0,7]])print('c:',c)d = c.reshape(2,6)print('c:',c)print('d:',d) 这里要注意的是，c和d共享内存数据存储内存区域，c变了，d也会变12345print(c[0])#修改c[0]c[0]=[-9,-8,-3]print('c:',c)print('d:',d) 我们可以通过dtype来获取元素的类型，我们可以在初始化的时候，指定dtype12345c = np.array([1,2,3])print(c.dtype) #int32d = np.array([1.1,3.3])print(d.dtype) #float64 下面，我们来看看常用的初始化方法 arange通过指定开始值，结束值和步长来创建一维数组，这里不包过终值1234567arange([start,] stop[, step,], dtype=None)np.arange(3)Out[51]: array([0, 1, 2])np.arange(1,10,3)Out[52]: array([1, 4, 7]) linspace通过指定开始值，终值和元素个数，来创建数组，这里包括终值12345np.linspace(1,10,5)Out[53]: array([ 1. , 3.25, 5.5 , 7.75, 10. ])np.linspace(1,2,3)Out[54]: array([ 1. , 1.5, 2. ]) np.zeros,np.ones这2个函数可以初始化指定长度或形状的全0或全1的数组1234567891011121314151617np.ones(3)Out[202]: array([ 1., 1., 1.])np.ones([2,2])Out[203]: array([[ 1., 1.], [ 1., 1.]])np.zeros(5)Out[204]: array([ 0., 0., 0., 0., 0.])np.zeros([4,3])Out[205]: array([[ 0., 0., 0.], [ 0., 0., 0.], [ 0., 0., 0.], [ 0., 0., 0.]]) np.empty可以创建一个没有任何具体值得数组1234567891011np.empty(2)Out[211]: array([ 7.74860419e-304, 7.74860419e-304])np.empty(2,dtype=int)Out[214]: array([ -1, 2147483647])np.empty((3,3),dtype=np.float64)Out[215]: array([[ 4.94065646e-324, 9.88131292e-324, 1.48219694e-323], [ 1.97626258e-323, 2.47032823e-323, 2.96439388e-323], [ 3.45845952e-323, 3.95252517e-323, 4.44659081e-323]]) 这要注意下，empty初始化的都是没有意思的值，不一定会初始化为0 2.2 存取元素这里直接粘贴一个例子，原始教程在这：http://old.sebug.net/paper/books/scipydoc/numpy_intro.html123456789101112131415161718&gt;&gt;&gt; a = np.arange(10)&gt;&gt;&gt; a[5] # 用整数作为下标可以获取数组中的某个元素5&gt;&gt;&gt; a[3:5] # 用范围作为下标获取数组的一个切片，包括a[3]不包括a[5]array([3, 4])&gt;&gt;&gt; a[:5] # 省略开始下标，表示从a[0]开始array([0, 1, 2, 3, 4])&gt;&gt;&gt; a[:-1] # 下标可以使用负数，表示从数组后往前数array([0, 1, 2, 3, 4, 5, 6, 7, 8])&gt;&gt;&gt; a[2:4] = 100,101 # 下标还可以用来修改元素的值&gt;&gt;&gt; aarray([ 0, 1, 100, 101, 4, 5, 6, 7, 8, 9])&gt;&gt;&gt; a[1:-1:2] # 范围中的第三个参数表示步长，2表示隔一个元素取一个元素array([ 1, 101, 5, 7])&gt;&gt;&gt; a[::-1] # 省略范围的开始下标和结束下标，步长为-1，整个数组头尾颠倒array([ 9, 8, 7, 6, 5, 4, 101, 100, 1, 0])&gt;&gt;&gt; a[5:1:-2] # 步长为负数时，开始下标必须大于结束下标array([ 5, 101]) 就2维数组来说 这是基本的获取方式，还有些高级的方法 使用整数序列这里简单来2个练习，原文例子很多，就是通过下标来筛选数据12345678910111213141516171819202122a = np.arange(-5,5,1)aOut[68]: array([-5, -4, -3, -2, -1, 0, 1, 2, 3, 4])a[[1,3,5]]Out[69]: array([-4, -2, 0])### 使用布尔数组按照传入的布尔数组，只有为True的才返回，也叫布尔型索引``` pythona=np.array([-3,1,5])aOut[72]: array([-3, 1, 5])a[[False,True,False]]Out[73]: array([1])a[[True,False,True]]Out[74]: array([-3, 5]) 3.附录（参考资料）文档：https://docs.scipy.org/doc/numpy-dev/reference/index.html#reference numpy快速处理数据]]></content>
      <categories>
        <category>Python-Numpy</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>Numpy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Cognos资料汇总贴]]></title>
    <url>%2F2017%2F08%2F01%2Fcognos-doc-main%2F</url>
    <content type="text"><![CDATA[以前搞过Cognos，写过很多基础的教程，应该是14年的样子，都在CSDN上，这里贴个汇总贴吧，想要看的同学可以去看看，希望有帮助。 ReportStudio入门教程：http://blog.csdn.net/column/details/ygy-reportstudio.html Framework Manage入门教程：http://blog.csdn.net/column/details/ygy-frameworkmanager.html Cognos函数手册：http://blog.csdn.net/column/details/ygy-cognos-function.html Cognos相关的其他资料（主页不同的类别下看看）：http://blog.csdn.net/yuguiyang1990 好了，感兴趣的同学，可以自行去看看，好久不搞了，估计有疑问也解决不了了…]]></content>
      <categories>
        <category>数据可视化-Cognos</category>
      </categories>
      <tags>
        <tag>数据可视化</tag>
        <tag>Cognos</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[小白学习Tableau-购物篮分析]]></title>
    <url>%2F2017%2F08%2F01%2FTableau-handbook-04%2F</url>
    <content type="text"><![CDATA[Tableau实例 关于购物篮的介绍可以参考数据分析案例-购物篮分析 目标我们想要分析的是顾客在购买商品的时候，哪些商品会同时购买。 下面，我们直接开始开发Tableau 数据源我们就是用Tableau默认自带的“示例-超市” 拖入两张订单表因为我们需要分析的是每个顾客，在购买A商品的时候，还会购买哪些商品。只使用一张订单表，不是很容易看出来，所以我们需要拖入2张订单表，以此来更方便的处理数据。因为我们要分析的是每个顾客，所以我们使用顾客ID去关联 拖子类别进行分析我们按照下图所示，进行拖拽 剔除无效的值手工剔除，好麻烦，如果数据是在数据库中，直接用SQL处理掉就可以了 这里，我们就快速的实现了购物篮分析，可以看到在购买某种商品时，同时购买其他商品的数量。 参考文章人人都是可视化分析师系列：用Tableau玩转购物篮分析]]></content>
      <categories>
        <category>Tableau</category>
      </categories>
      <tags>
        <tag>数据可视化</tag>
        <tag>Tableau</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[小白学习Tableau-堆叠条按值排序]]></title>
    <url>%2F2017%2F07%2F30%2FTableau-handbook-03%2F</url>
    <content type="text"><![CDATA[序昨天学习了下堆叠条形图，刚刚看到个类似的教程，说的是，在堆叠条中按值进行排序，挺有意思的。 又学习到了一招，简单分享下。 按值在堆叠条中对段进行排序我们先实现一个简单的堆叠条， 使用维度：地区、类别 使用度量：销售额 下面，我们来看下，是怎样让每个类别的数据块按照销售额排序的。 我们观察下，上面的图，每个地区一个颜色，默认应该是按地区来排序的，每个数据条排序都一样。 我们首先，在颜色“地区”上右键单击，选择“属性” 这里的“维度”、“度量”我都可以理解，但是并没有找到“属性”在Tableau中是怎样定义的，按照以前对BI中维度模型的概念来理解的话， 比如，日期维度，包含3个层级，年、月、日，层级月的属性的话，可能是月份名称、月份中文名称等等。我们选完属性之后，会变成这个样子 然后，我们选中，维度“类别”和“地区”，创建一个合并字段 这个合并字段，是个什么东西呢？其实就是新增了一个联合维度，就是类别和地区的一个笛卡尔积，内容是这样的 然后，我们把这个合并字段，拖到详细信息上， 然后，我们在合并字段上，选择排序 我们，依次，选择“降序”，“按销售额来” 最后结果，是这样的 实例呢，在Tableau Public上，练习04-堆叠条按值排序 最后的话，后面还得详细理解下这里用属性和合并字段一起使用的这个操作，有领悟的话，会在分享。 附录官方教程：按值在堆叠条中对段进行排序]]></content>
      <categories>
        <category>Tableau</category>
      </categories>
      <tags>
        <tag>数据可视化</tag>
        <tag>Tableau</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[小白学习Tableau-堆叠条形图]]></title>
    <url>%2F2017%2F07%2F30%2FTableau-handbook-02%2F</url>
    <content type="text"><![CDATA[序昨天在看水足迹那个可视化题目的时候，就想做一个堆叠条形图，但是发现只有一个维度，怎么也拖不出来，后来改了下数据源，成功实现了。今天搜到个例子，发现了解决办法，只能说明，还是对Tableau不熟啊，没有能领悟Tableau的内涵。 堆叠条形图教程中介绍了2种方法，我们都来实践一下。这里面，最大的收获，就是原来那个“度量名称”和“度量值”是可以拖拽过去使用的，我也是醉了，这个操作得好好研究下，理解下Tableau的机制。 这里的度量名称，应该就是所有度量的一个集合；度量值应该就是“度量名称”集合中选定的度量。 这里我们就用 http://www.makeovermonday.co.uk/ 上的数据 对每个维度上使用一个单独的条首先，我们将“食物”维度，拖到列上， 然后，我们需要观察的是3种水足迹的值，并让他们显示成堆叠图的样子 我们把度量名称，拖到颜色上 因为，我们只看3个水足迹的量，我们就筛选下 （这个颜色是我之前设置过的，大家操作完，颜色可能和我不一样，但样式是一样的）就这样，我们完成了，列上是每一种食物，然后行上面是选定的3中水足迹，一个简单的堆叠图就完成了。 对每个度量使用一个单独的条这个操作其实就是和上面的操作的相反我们将度量名称拖到列上，并筛选 然后，将度量值拖到行上 最后，将维度，食物拖到颜色上 这样，我们就在3个度量值上，看食物维度的一个堆积情况。好了，堆积图的例子就完成了，主要是理解下Tableau的思想。 小例子，发布在Tableau Public上：练习03-堆叠条形图 附录（参考资料）官方教程：使用多个度量创建堆叠条形图]]></content>
      <categories>
        <category>Tableau</category>
      </categories>
      <tags>
        <tag>数据可视化</tag>
        <tag>Tableau</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[小白学习Tableau-标签云]]></title>
    <url>%2F2017%2F07%2F30%2FTableau-handbook-01%2F</url>
    <content type="text"><![CDATA[序周末参加了2天的Tableau培训，发现这个东西做可视化分析还是很方便的，用户体验也很好。 也听了很多大师的介绍，受益良多。不管怎样，要开始学些这个Tableau了。之前也有做过IBM Cognos的开发，2个产品对比一下，从直观上来看，就是Tableau的可视化效果好很多，而且还融合了一些分析功能，挺不错的。很久之前就知道了Tableau其实，只是一直都没有去研究她。学习的一开始呢，先是模仿，熟练掌握了Tableau之后，就可以任意发挥了。Tableau入门的话，官方就有很多的资料，挺全的，还有视频教程。 标签云之作这个比较简单，主要参考了jiyang大神的教程，后面有链接我们使用Tableau自带的示例库 我们主要就使用“类别”、“子类别”、“销售额” 我们把子类别拖到文本上 这里会显示，所有的子类别，然后呢，我们希望子类别可以根据销售额的大小而控制大小 把销售额拖到标记-大小上 默认的话，可能会显示这个树状图，但是我们并不想要这样，我们想要显示文本 我们修改下，我们把自动，修改为文本 好了，已经可以按销售额的大小来显示子类别的内容了当然，我们一般见到的标签云，都是有颜色的，那我们就继续用销售额的大小来控制颜色 将销售额拖到颜色上 这样呢，我们就用销售额控制了文本的大小和颜色， 一个简单的标签云就实现了 好了，这个例子就是这样简单，小例子，发布在Tableau Public上， 练习02-销售额标签云 附录（参考资料）参考学习jiyang大神的作品：https://public.tableau.com/profile/jiyang#!/vizhome/_3516/sheet0]]></content>
      <categories>
        <category>Tableau</category>
      </categories>
      <tags>
        <tag>数据可视化</tag>
        <tag>Tableau</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[BeautifulSoup教程（2） - 实例-解析博客专栏]]></title>
    <url>%2F2017%2F04%2F20%2Fbs-handbook-02%2F</url>
    <content type="text"><![CDATA[前几天学习了下Beautiful Soup的使用，本来想多写些内容的，但是发现，官方的介绍实在太详细了，每种方法基本都覆盖到了， 直接看官方的例子就足够了，而且还有一个中文版的，这里的话，就简单实践下，介绍几个常用的方法和一些小经验。 官方文档：https://www.crummy.com/software/BeautifulSoup/bs4/doc/ 这里，我们就简单的解析下博客专栏，https://blog.hellobi.com/ 这里的话，没有做太多的限制，我们直接解析就可以 1. 分析网页我们再Firefox中，使用 Firebug很方便 这里的话，文档结构也很清晰，很适合我们练习 基本代码，我们获取网页信息12345678910111213# -*- coding: utf-8 -*-import urllibfrom bs4 import BeautifulSoupimport sysreload(sys)sys.setdefaultencoding('utf-8')#加载网址，获取当前页面def getHTML(url) : page = urllib.urlopen(url) html = page.read() return html 2.常用类 123html = getHTML('https://blog.hellobi.com/')soup = BeautifulSoup(html, "html.parser") 这里，我们初始化Beautiful Soup，使用“html.parser”,这是一个默认的解析器，他还有其他的解析器，官网有介绍，这里就不说了，其他也没有测试过 这里，顺便说下Python中查看类的帮助信息，使用dir()函数，可以查看类的属性和方法列表12print type(soup)print dir(soup) 我们还可以使用help函数，查看详细的帮助信息 1print help(soup) Beautiful Soup是最基础的类，其他的还有Tag，这个用起来和HTML中的标签类似 12345print soup.titleprint type(soup.title)#print soup.headprint type(soup.head) 这里，的title，head都是HTML中的tag，也是Tag类的对象 123print soup.title.stringprint type(soup.title.string)print dir(soup.title.string) 然后，我们需要使用Tag的内容时，就用到了NavigableString 3.常用函数123456789101112131415161718blog_index=1for blog in soup.find_all('div', class_='blog-item'): print '----------------------------------------------------------' print '第%s篇博客' %(blog_index) title = blog.select_one('div.caption &gt; h2 &gt; a') print '博客标题: ',title.string author = blog.select_one('div.caption ul a') print '作者: ',author.text.strip() vote = blog.select_one('div.cp div.blog-votes span') print '推荐次数: ',vote.string info = blog.select_one('div.cp div.blog-views span') print '阅读次数: ',info.string blog_index+=1 上面的代码，就是遍历的首页的所有博客信息，很简单，就是一个find_all()和一个select_one() find_all() select_one() select() 方法中传入字符串参数,即可使用CSS选择器的语法找到tag: 思想其实都一样，就是根据一定的规则，找到我们想要的标签 后面的话，我们再找到总页数，遍历一下，就可以获取所有的博客基本信息啦1https://blog.hellobi.com/?page=2 传递页码就可以了 好了，这里就举这一个简单的小例子，大家多在实践中使用就好了]]></content>
      <categories>
        <category>Python-爬虫</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>BeautifulSoup</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[BeautifulSoup教程（1） - 简介及安装]]></title>
    <url>%2F2017%2F04%2F14%2Fbs-handbook-01%2F</url>
    <content type="text"><![CDATA[最近在学习Python，按照一些博客练习爬虫，最简单的步骤，就是访问一个主页，根据正则表达式去获取我们想要的标签数据； 比如这样：1234567891011#加载网址，获取当前页面def getHTML(url) : page = urllib.urlopen(url) html = page.read() return htmldef getImage(html) : reg = r'src="(.+?\.jpg)"' reg2 = r'&lt;img alt="(.+?)" src="(.+?\.jpg)' image_reg = re.compile(reg2) img_list = re.findall(image_reg,html) 简单的话，这样还好，如果复杂些的话，像我一样对正则表达式不熟悉的话，可能就不太好实现了， 后面发现这个beautifulSoup解析HTML很方便，这里简单学习下， 官网地址：https://www.crummy.com/software/BeautifulSoup/ 还有中文文档：https://www.crummy.com/software/BeautifulSoup/bs4/doc/index.zh.html 1. 简介这里说的不错，Python爬虫利器二之Beautiful Soup的用法 2. 安装Python里面安装东西很方便，直接使用pip就行了 pip install beautifulsoup4 3.小例子我们先写个小例子看看123456789101112131415161718 # -*- coding: utf-8 -*-import urllibimport refrom bs4 import BeautifulSoup#加载网址，获取当前页面def getHTML(url) : page = urllib.urlopen(url) html = page.read() return htmlhtml = getHTML('https://movie.douban.com/top250')soup = BeautifulSoup(html, "html.parser")for img in soup.find_all('img'): print img.get('src') 这里，我们就输出了所有的img标签 后面，我们再来继续练习使用]]></content>
      <categories>
        <category>Python-爬虫</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>BeautifulSoup</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Kettle手册（十二）- 控件使用-从步骤插入数据]]></title>
    <url>%2F2017%2F04%2F14%2FKettle-handbook-12%2F</url>
    <content type="text"><![CDATA[这里介绍一个控件的小功能，也是最近才发现的，之前在“表输入”中要使用参数的话，一般都是使用变量，其实，还有个功能也可以尝试使用整体流程就是这样，我们第一个 query_paramter，就是查询了我们想设置的参数然后，就是我们真正需要的，我们再表输入中，使用 “?”来占位，然后“从步骤插入数据”，选择上一个步骤，然后会将数据替换占位符最后，我们将文件导出即可，奥对了，我们可以改成日志控件，直接输出查看刚刚，上面还有一个“执行每一行”，这个就是，如果我们有多个参数，就可以使用这个参数了，很方便，好了，就介绍到这里先。]]></content>
      <categories>
        <category>ETL-Kettle</category>
      </categories>
      <tags>
        <tag>Kettle</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Kettle手册（十一）- 用PGP加密、加密文件]]></title>
    <url>%2F2017%2F04%2F11%2FKettle-handbook-11%2F</url>
    <content type="text"><![CDATA[看到有同学提问，以前也没用过，百度了一下，找了些资料，这里记录下。 1. 安装gpg4win这个gpg4win是干嘛的呢，我们可以去他的官网看看：gpg4win目前，只知道他是加密的，这个是对Windows平台使用的这里可能还有个PGP的概念，看看百度百科 好了，具体概念，大家可以自行找找，我们下载下来，然后安装一下即可这个是昨天安装的，就不粘贴步骤了，安装完后，我们要先创建一个证书的东西，我们打开这个管理界面打开后，是这样一个界面，（网上有这个的安装配置教程，这里也简单介绍下，不清楚的可以再百度看看）我们新建一个Certificate我们选择一个加密方式，使用第一个就可以了我们输入些基本信息然后next就可以然后，我们得输入一段密钥好了，这里，就配置完成了 2. 用PGP加密文件好了，这里，我们新建一个作业，我们主要使用这2个控件一个很简单的流程，我们做些简单的配置，一个是GPG的目录（就是我们上面安装的那个）还有就是，我们的要加密的文件和一个目标文件名，注意，这里我们得填写一下“用户ID”，就是我们前面新建的那个用户名就可以了这里，可以勾选一下，目标是一个文件好了，然后，我们执行下就可以了我们源文件：加密后的文件：下面，我们再看看，怎样解密 3. 用PGP解密文件知道了加密，解密也是一样的，这里的话，配置和上面差不多，这里，我们要填写一个“密钥”，就是我们上面创建时，输入的一个密码我们运行一下，解密后，是一样的好了，就简单介绍到这里]]></content>
      <categories>
        <category>ETL-Kettle</category>
      </categories>
      <tags>
        <tag>Kettle</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Kettle手册（十）- 跨库查询]]></title>
    <url>%2F2017%2F04%2F10%2FKettle-handbook-10%2F</url>
    <content type="text"><![CDATA[Kettle整体使用起来，还是很方便的，熟悉应用了之后，就是对控件的熟悉和使用了，只要思路有了，就是整合下Kettle中各个控件的使用就行。这里，简单介绍下一个“跨库查询”的控件。有的时候，我们一个脚本，可能只是临时性的，或者需要实时的去查一下，同步到数仓的话，可能不太方便，我们就可以使用跨库查询的控件用到的表信息 1. 数据库连接(Database Join)我们先用这个控件来实现一下用起来也很简单表输入：是我们第一个库中的SQL数据库连接：是我们另一个库的SQL我们用关联的字段放在where条件后，使用“?”来占位，并在下面，选择要传入的参数默认的话，是JOIN，我们也可以勾选Outer Join，然后，我们看下，输出就行这是后面导出的文件，这里，我们就简单实现了跨库的查询 2. 数据库查询我们再来看另一个控件，“数据库查询”，这个控件同样可以实现跨库，但是有一个小问题首先，我们使用上一次的数据来看我们执行下，结果看上去是一样的这其实有个隐藏的问题，我们再增加几条记录看看比如：现在1号有2条记录，正常的话，我们导出也是要有2条的我们执行下看看我们会看到，数据并没有增加，这是控件导致的，先获取左边的结果集，然后一条一条去右边匹配；匹配到第一条记录后，就会跳出，直接去匹配下一个，所以，我们有2条记录，也只会找到第一个。这并不是我们想要的，我们再试下第一个控件使用这个“数据库查询”控件的话，可以通过将1-N关系汇总，将N的一方，放在前面最后的结果也是可以的]]></content>
      <categories>
        <category>ETL-Kettle</category>
      </categories>
      <tags>
        <tag>Kettle</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Kettle手册（九）- 发送邮件]]></title>
    <url>%2F2017%2F03%2F30%2FKettle-handbook-09%2F</url>
    <content type="text"><![CDATA[在Kettle里面，我们每天执行完调度之后，想要监控下JOB的执行状态，通常我们可以会发送邮件，可以的话，还可以发送短信。 在Kettle里面，发送邮件很方便，这里，我们就简单的测试下。 1. 在作业中发送简单邮件我们只需要使用到这个控件就可以了，这样，一个简单的发送邮件流程就好了 控件的配置：收件人，抄送啊，信息，自行填写就行，多个收件人，使用“空格”分隔在服务器这里，我们填上服务器的信息就可以了这里是邮件消息的一些配置，暂时先到这里，我们测试下结果然后，查看邮箱，我们会接收到这个邮件，刚刚简单测了下这个“回复名称”，就是这里试过中文，会有问题，有乱码，可能是Windows下的原因，没有再去测试验证就是收到邮件时的一个发件人的名称，不同邮箱显示的不一样 2. 增加附件附件的话，也很简单，上面的面板中直接配置就可以了然后，我们需要将待发送的邮件，添加到结果集中在控件中，我们添加好文件就行了。我们再次发送，验证下好了，附件也可以了，思路就是这样的，实际应用时，可能还有些问题得注意下 3. 自定义邮件内容到这里，我们会看到，邮件的正文内容，可能并不是我们想要的， 我们想要的可能是这样的信息这就需要自定义正文内容，我们需要勾选下面这个选项这里是可以使用变量的，我们可以拼接HTML来实现好了，邮件的介绍，大概就这些，在转换中，也是可以使用的，大同小异]]></content>
      <categories>
        <category>ETL-Kettle</category>
      </categories>
      <tags>
        <tag>Kettle</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Kettle手册（八）- 循环]]></title>
    <url>%2F2017%2F03%2F29%2FKettle-handbook-08%2F</url>
    <content type="text"><![CDATA[有的时候，我们想要在Kettle中实现这个循环的功能，比如，批量加载数据的时候，我们要对10张表执行同样的操作，只有表名和一些信息不一样，这时，写个循环就省事儿多了 1. 遍历结果集实现这里的话，我们主要是通过一个将结果集返回，然后通过转换的设置来实现的 1.1 query_the_result这个转换，只要是将我们要遍历的结果集返回，表输入，我们就是返回了5条记录，来做遍历复制记录到结果，这个控件的作用，就是我们可以在后面的转换继续使用这个结果集。 ##1.2 traverse_the_result这里呢，我们就是需要遍历的转换了，这里，我们只是获取结果集，然后将结果集输出还有一个很重要的一步，怎样让这个转换可以根据结果集的条数，去循环执行呢？就是这个“执行每一个输入行”我们执行下看看 2. 使用JS实现网上有很多的例子，介绍怎样用JS来控制循环，这里我们也简单的测试下 2.1 query_the_result这一步，和上面的一样，就是将结果集返回 2.2 travers_the_result这里主要是使用JS将结果集进行遍历，通过JS，将一些结果存放到变量里面，在后面的操作中就可以使用了，通过${xxx}的方式使用这个其实和Java、JS里面循环思路一样，通过结果集的总数“total_num”和下标“LoopCounter”进行判断 2.3 evaluate_the_loop_count这一步，就是判断下标的值和结果集的总数，进行对比， 2.4 print_the_log输出下，我们想要使用的变量 2.5 manage_the_loop_index这一步，给下标加一，然后获取下一条记录好了，执行下，我们看看好了，循环的使用先介绍到这里]]></content>
      <categories>
        <category>ETL-Kettle</category>
      </categories>
      <tags>
        <tag>Kettle</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Kettle手册（七）- 资源库的使用]]></title>
    <url>%2F2017%2F03%2F29%2FKettle-handbook-07%2F</url>
    <content type="text"><![CDATA[1. 为什么使用资源库之前，我们新建转换或者作业的时候，都是直接保存在本地，而如果我们是多人开发的话，除了使用SVN等版本控制软件，还可以使用Kettle的资源库，他会将转换、作业直接保存在数据库中，而且，连接资源库的话，我们就不需要每一次都新建数据库连接了，用起来还是蛮方便的。 2. 新建资源库Kettle7.0里面，是在右上角这个Connect来连接的 2.1 资源库的类型资源库有3中类型Pentaho RepositoryDatabase Repository（使用数据库存储）File Repository（使用文件存储） 2.2 新建Pentaho Repository我们单击上面的get started 之后，就会进入新建界面http://localhost:8080/pentaho一开始还没搞懂这个Server到底怎么启动，后来google了半天发现后来又找到了这个，应该是要安装其他的组件才行，这个类型的库就放弃吧。。 2.3 Database Repository好了，这回，我们选择哪个database的资源库我们填一个connection的名字，然后配置一个资源库的连接就可以了，最好给kettle新建一个数据库使用至于数据库连接的话，和转换里面是一样的，大家可以自行新建一个配置好，以后，大家选择Finish就可以了，然后，我们可以连接下这个库，注意下，这里的用户名和密码，默认是admin/admin，大家直接登录就好了，这是Kettle自己初始化的这个怎么改呢，暂时还没有发现，待研究，等我再google看看，估计官网上会有。（找了下，发现了在哪改密码，就是刚刚的搜索资源库)连接后，我们正常使用就好了，没啥两样，会多一些功能，比如，探索资源库这里我们再保存作业和转换的话，会直接保存在数据库中，而且，很好的一个功能，个人感觉，就是数据库连接只需要创建一次，在哪里都可以用了，不需要再次创建。 2.4 File Repository这个和database的资源库，就差不多了，只不过是基于文件的，保存在本地就可以了这个就和Eclipse一个工作区差不多，转换、作业都保存在这个目录下好了，关于资源库，就简单的说这些了，大家可以自行连接，试试。]]></content>
      <categories>
        <category>ETL-Kettle</category>
      </categories>
      <tags>
        <tag>Kettle</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Kettle手册（六）- Hop小记]]></title>
    <url>%2F2017%2F03%2F29%2FKettle-handbook-06%2F</url>
    <content type="text"><![CDATA[1. 什么是Hop在我们前面，使用Kettle过程中，控件与控件之间的连线，这里，我们详细介绍下它，它在Kettle中叫Hop（跳）。 2. Hop的发送方式（转换）在转换中，一般情况，控件和控件之间只有一个Hop，当然，如果需要的话，我们拖了2个控件出来，像这样：Kettle会提示你，下面的信息，让你选择，数据发送的方式 2.1 分发记录目标步骤轮流接收记录，其实就是你一条，我一条，轮着接收数据，这个我们试一下就知道了，我们执行下，看看这个结果试试，我们再步骤度量中，可以看到，a.txt和b.txt分别写入的数量看看结果文件，就是这样的 2.2 复制记录所有记录同时发送到所有的目标步骤，这个看起来就简单多了，比如上面的例子，2个文本文件会接收到同样的所有的数据，我们也试一下结果文件的话，就是2个节点，接收到的数据都是一样的 3.Hop的状态（作业）在作业中，Hop主要用来控制流程有3种状态，一个锁，一个绿色的对号，一个红色的叉号简单来说，：表示无论上一步执行成功还是失败，都一定会执行下一步：表示上一步执行成功才会执行下一步：表示上一步执行失败执行下一步比如我们上面的例子，我们的转换执行成功后，就结束了，如果转换执行失败了，我们就发送邮件。]]></content>
      <categories>
        <category>ETL-Kettle</category>
      </categories>
      <tags>
        <tag>Kettle</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Kettle手册（五）- 实例-增量同步数据]]></title>
    <url>%2F2017%2F03%2F28%2FKettle-handbook-05%2F</url>
    <content type="text"><![CDATA[综合前面的几个例子，我们这里来是实现下增量数据的同步。这里只是分享一种方法，实际工作中，还会有其他更好的方案。增量同步的整体思路一般就是：首先拿到这张表的增量数据，怎么拿增量呢，源表需要有一个时间字段，代表该条记录的最新更新时间（及只要该条记录变化，该时间字段就会更新），当然有时间字段最好了，没有的话，可能需要做全表对比之类的操作；正常情况下，业务系统的表中都是有主键的，我们拿到增量数据之后，需要判断该记录的新插入的，还是更新的记录，如果是更新记录，我们需要先将数据加载到中间表，然后，根据主键将目标表中已存在的数据删除，最后再将本次的增量数据插入到目标表。 1.配置表的设计（元数据表）首先我们需要一张配置表，来保存我们要增量同步的表的基本信息1234567--元数据表create table tm_etl_table( table_name varchar(50), --表名 is_run int , --调度状态 update_time timestamp,--表数据更新时间 etl_insert_time timestamp --记录更新时间); 我们初始化一条记录，我们就以这张ods_tm_book表一些基础表准备 12345678910-- 源表create table tm_book(id int,book_name varchar(10),latest_time timestamp);-- 源表数据初始化insert into tm_book(id,book_name,latest_time)select x,x||'_name',clock_timestamp() from generate_series(1,10) x;-- 目标表和中间表create table ods_tm_book(id int,book_name varchar(10),latest_time timestamp,etl_insert_time timestamp);create table staging_tm_book(id int,book_name varchar(10),latest_time timestamp); 源表中的数据 2.同步数据的流程开发整体流程是这样的，注意下，这个只是为了简单演示了这个增量的例子，实际应用的话得修改，这是有漏洞的。 2.1更新元数据表的状态并获取表更新时间就是我们第一个状态，我们更新tm_etl_table表，更新is_run=0，表示我们开始同步数据了，update_time，初始化为 ‘1970-01-01’，表示我们要拉取所有的数据这里，我们将该表的更新时间作为变量，我们会在后面的转换中使用 2.2 加载数据到中间表我们这里，直接表对表，将数据插入到staging其中，表输入中，我们需要根据前面的更新时间变量，获取增量数据，注意，需要勾选上“替换SQL语句中的变量”这里，我们直接就表输出到中间表，每次都需将清空表数据 2.3 加载数据到目标表这里，主要有3段脚本（为了方便，就这样吧），根据主键ID，清空目标表数据，然后，将数据插入到目标表，最后，更新tm_etl_table表中的记录状态好了，用Kettle实现一个增量的逻辑大概就是这样了， 3.小结这里整理几个问题 3.1 中间表这里的话，使用了中间表，Kettle中是有一个控件的，应该叫那个“插入/更新”，可以根据主键将数据更新掉，这个控件之前使用时，发现很慢，就一直没用，后面的话，可能会写个例子，简单测试看看。使用中间表，缓存下数据，也是不错的方法。 3.2 增量流程目前公司中，增量抽取，是这样的，首先各个业务系统的数据导出到文本文件，然后批量将文件加载到数据仓库中（这里使用循环加载的）。因为每天的数据量比较大，如果知己到表的话，会很慢，使用文件，一些数据库都有批量加载的命令，很快很方便，比如：PostgreSQL中的copy命令，Greenplum中的外部表，还有Mysql中的load data等等。]]></content>
      <categories>
        <category>ETL-Kettle</category>
      </categories>
      <tags>
        <tag>Kettle</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Kettle手册（四）- 变量的使用]]></title>
    <url>%2F2017%2F03%2F28%2FKettle-handbook-04%2F</url>
    <content type="text"><![CDATA[我们在这一回，介绍下，Kettle中全局变量的使用，我们前面说过的配置文件，其实就是配置全局变量的地方Kettle手册（三）- 配置文件的使用及密码加密 1. 全局变量 就是我们上面说的kettle.properties文件，我们在里面定义的变量，我们可以在所有的转换或者作业中获得到，比如，我们前面，说的数据库参数之前，我们已经在数据库连接中测试过，是可以，这里，我们输出下这个变量，看看 1.1 输出变量的值我们这里，用到了“获取变量”这个控件我们单击，”Get Variables”,就可以获取到当前的全局变量信息我们选择几个输出试试还有一个，”日志“控件，拖好之后，我们直接执行，日志中，我们会看到，我们定义在文件中的参数（加密的参数，我没有重启，所以显示的还是原来的）那我们，可不可以，动态的增加变量呢？ 1.2 动态增加变量刚刚也在网上找了些资料，尝试了下，这里简单分享下（貌似，这得算是对局部变量的操作，暂时就放在这里吧）我们先试下在转换中设置变量，作业中也是可以使用的，我们后面再说测试流程是这样的， 我们再表输入中，有2个时间参数，然后作为变量比如，有这样一个场景，我们每天需要定时调度一些SP，SP都有开始时间，结束时间，调用时，需要传参数进去，这个时候，我们在使用Kettle的时候，就可以通过这样的方式，去设置变量，然后再调用SP我们单击获取字段后，就可以了，这里可以修改变量存在的范围执行后，输出，后面，我们就可以使用这2个时间变量了这里使用的时候，也遇到一个问题，就是变量的默认值，一直都没有生效，不知道为什么，不管是，静态值，还是变量值，都没有办法，待研究。 2. 局部变量（命名参数） 在kettle中，相对于全局变量，我们还可以使用局部变量。感觉，这个全局变量，局部变量，都是相对而言的，就网上大部分资料来说，Kettle中的局部变量就是“命名参数”我们再转换中，右键单击，选择，转换设置 我们选择，“命名参数”，定义一个变量，我们给一个默认值然后，在日志中，将变量输出我们执行下，这个转换，运行时的界面，我们可以看到，这个参数是可以动态改变的，或者，我们再命令行调这个转换的时候，同样可以给他赋值运行结果，这个就是简单的局部变量了]]></content>
      <categories>
        <category>ETL-Kettle</category>
      </categories>
      <tags>
        <tag>Kettle</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Kettle手册（三）- 配置文件的使用及密码加密]]></title>
    <url>%2F2017%2F03%2F28%2FKettle-handbook-03%2F</url>
    <content type="text"><![CDATA[好了，我们上一回，练习了一个从数据库导出数据到Excel的例子，我们想一下，如果有很多个转换，我们没链接一次数据库，是不是都需要重复的输入那些数据库地址啊，数据库啊，用户名啊之类的。其实是不用的，我们可以使用变量的方式，写在配置文件中，下面，我们来看看。而且，我们平时开发，都有开发环境、UAT环境、生产环境，连接的地址都不一样，也不可能手动的去修改。 1. Kettle的配置文件 配置文件在哪呢？Windows下，是再当前用户的目录下，一般再C盘，Users下面，有一个当前用户的文件夹，下面有.kettle文件夹进入之后，我们会看到一个kettle.properties的文件，我们的数据库配置信息，就可以放在这里， 我们打开之后，编辑一下保存后，我们要重新启动下Kettle，因为这个配置文件是启动时加载的重启后，我们将上一次，配置的转换打开，使用变量替换下之前的配置，Kettle中，我们使用${xxx}，表示引用一个变量，执行时，会自动替换我们测试下，同样时可以成功的。好了，这样，以后，不管是，数据库地址变化，还是部署生产，我们只需要修改配置文件就可以了。 2. 密码加密 这里，顺便说下，加密的问题，比如，我们上面的数据库密码，是明文的，这样是不太安全的，而实际上，我们都是需要对密码进行加密的我们进到Kettle的安装目录我们会看到，这里有一个Encr.bat，这就是可以加密的脚本使用方法我们输入1Encr.bat -kettle postgres 执行后，会生成，这样一个加密后的密码，然后，我们可以使用这个加密后的字符串，替换我们的密码1pg_password = Encrypted 2be98afc86aa7f2e4cb79ff228dc6fa8c 大家可以试下，这样也是可以的，好了，这个例子就到这。]]></content>
      <categories>
        <category>ETL-Kettle</category>
      </categories>
      <tags>
        <tag>Kettle</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Kettle手册（二）- 将数据导出为Excel]]></title>
    <url>%2F2017%2F03%2F27%2FKettle-handbook-02%2F</url>
    <content type="text"><![CDATA[好了，我们先来看第一个例子，就是怎样将数据库中的数据，导出为Excel。平时，如果我们需要将数据导出Excel的话，我们可能会直接复制，然后粘贴出来，但是数据量大的话，就不好用了；或者使用Java等开发语言，写代码，导出Excel；或者一些数据库连接工具自带的导出功能。其实，我们用Kettle的话，还是很方便的，但是平时用下来，Kettle的这个功能还是有些缺陷的，比如导出Excel2007+的时候，经常会报错，我一直也没有解决，这次记录博客顺便研究看看。 1. Kettle的下载及使用 正式开始之前，我们简单说下Kettle的安装配置啥的，Kettle是绿色的，下载之后，直接运行就可以了刚刚在网上下了个最新版的，后面，我们就是用这个7.0版本介绍官网地址：Kettle官网 他这个网站，应该是不太好访问，有VPN的话，可以用起来，下载的话，大概800M左右，后面看看上传一份，昨天为了下载，现冲了个蓝灯的会员解压以后，目录大概是这样的，我们会看到，这里有.bat文件和.sh文件，.bat就是我们在windows下使用的，.sh就是在Linux下使用的，我们找到 Spoon.bat这个文件，就可以启动Kettle了，奥，对了，得先安装下Java打开后，就是这样了，都是图形界面的，很好用Kettle中，主要有2中任务，一个是作业，一个是转换。一般来说，转换是一系列具体的操作，比如：调度SP，导出Excel等等；作业的话，就是按照一定流程来调度一系列转换。大概是这样，实际上，他们也是可以嵌套调用的，我们后面可以再讨论。 2. 第一个转换-将数据导出为Excel 为了实现这个功能，我们需要： 连接到数据库 导出为Excel 首先，我们新建一个转换，新建，之后，我们可以看到，工具箱中，有很多的控件，我们都可以使用，很多我也没有用过，大家可以自行去尝试使用好了，下面，我们就开始介绍我们这次的主题，导出数据到Excel既然，是导出数据，说明我们肯定有一个源头，一个目标，源头是我们的一个数据库，我们得先连接到这个数据库 新建数据库连接我们在主对象库中，DB连接上，右键单击，新建在这里呢，我们可以看到，有很多的数据库可以选择，我们只需要填写基本的连接信息就可以了我们这里连接的是Postgresql，配置好后，测试下，（坑，刚刚在windows上装的数据库，一直连不上，白名单都加好了，就是不行，结果是防火墙忘关了。。）好了，可以连接到数据库了，下面，我们得把数据导出啊，我们需要使用输入这个控件输入下面，有很多的控件，我们这次只使用表输入，因为我们是直接从数据库中拿数据这里直接就是拖拽的，拖过去就行了，双击之后，可以编辑，这里我们就使用刚才的数据源连接，然后查询一张表，表的话，随便create一张就可以了，我们还可以预览数据源头好了，同样的思路，我们需要一个目标，就是输出了，输出到Excel同样的，我们托好之后，双击就可以编辑了，这里，我们主要关注2个配置，一个是excel保存地址，和字段我们选择一个地址，然后得，看下字段那个tab，我们单击，获取字段，就可以从源头获取表中的字段了，当然，我们可以只导出，我们需要的字段，一步一步来的话，上面获取，可能会获取不到，因为，有一步，需要将2个控件，连起来，源头有了，目标也有了，得让他们关联起来啊，再Kettle中，这个连线叫做Hop（跳），就像一个管道一样，将数据流从一个点，指向另一个点。都好了，以后，我们就运行下和Java里面，一样，绿色的话，就代表成功了我们看下文件好了，我们的第一个例子，就成功了，还是很简单的，主要就是Kettle中控件的熟悉。]]></content>
      <categories>
        <category>ETL-Kettle</category>
      </categories>
      <tags>
        <tag>Kettle</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Kettle手册（一）- 序及Kettle简介]]></title>
    <url>%2F2017%2F03%2F27%2FKettle-handbook-01%2F</url>
    <content type="text"><![CDATA[1. 序 好久没有写博客了，新的一年总得留下点儿什么。目前主要负责数据仓库这一块任务，平时用用Kettle、SSIS这类ETL工具，而且工具的使用整理起来会方便些。所以先从Kettle开始，一点点整理下最近BI开发中掌握的知识。以前有做过BI报表Cognos开发还有些入门级的Java，都在CSDN博客上，感兴趣的同学可以去看看：于贵洋的博客好了，下面就根据自己的经验和理解，整理下Kettle的知识。 2. Kettle简介 Kettle这东西是干嘛的呢？Kettle是一个开源的ETL工具，所以基本的数据抽取、转换、加载，他都可以。比如：我要把一个mysql数据库的数据同步到一个Postgres数据库，我们有哪些办法呢?大概会有: 将数据导出为文本文件，使用PG的copy命令直接加载 数据量少的话，直接拼接成insert脚本，批量插入 一些开源的小工具，提供2种数据库直接的同步 Kettle 等等方法再比如：我每天需要统计一些系统中的异常数据，导出为Excel，用邮件发送给指定的开发人员处理，该怎样做呢？ Java或者其他开发语言做定时任务 Kettle 和其他的ETL工具相比，他有什么优势呢？ Kettle是基于Java开发的，是开源免费的，大家可以直接在网上下载；跨平台，Windows，Linux都可以使用；使用起来简单快捷。 既然开源，相比于其他收费产品，劣势也就很显然了，比如稳定性啊，BUG修复处理啊，而且基于Java，性能上会差些。当然都是相对来说，一般数据量使用或者逻辑不复杂的话，使用起来是很适合的。 刚刚也在社区上，发现了Kettle的视频，kettle视频，大家可以看看，应该用的到。Kettle的基本介绍就这些，后面会根据实际的例子，来介绍下Kettle的使用。]]></content>
      <categories>
        <category>ETL-Kettle</category>
      </categories>
      <tags>
        <tag>Kettle</tag>
      </tags>
  </entry>
</search>
